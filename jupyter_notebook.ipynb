{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97YtTTuS0JAN",
        "outputId": "4c9a1d6f-8261-4d97-8121-fa126129ef12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing D7 ...\n",
            "Processing D58 ...\n",
            "Processing D73 ...\n",
            "\n",
            "=== EMD Bias Table ===\n",
            "Dataset  Group  EMD value  p-value Exhibit data bias?\n",
            "     D7 Female   0.005531   0.0375                Yes\n",
            "     D7   Male   0.002973   0.0285                Yes\n",
            "    D58 Female   0.011548   0.0000                Yes\n",
            "    D58   Male   0.012620   0.0000                Yes\n",
            "    D73 Female   0.006623   0.0365                Yes\n",
            "    D73   Male   0.005388   0.0390                Yes\n",
            "\n",
            "=== Detection Metadata (for reproducibility) ===\n",
            "Dataset   gender_col_used                label_col_used      N  N_female  N_male\n",
            "     D7            gender                        cardio  70000     24470   45530\n",
            "    D58               Sex               Diabetes_binary 236378    123431  112947\n",
            "    D73 sex_0male_1female hospital_outcome_1alive_0dead  19051      8546   10505\n",
            "\n",
            "Saved: emd_bias_table.csv, emd_bias_table.xlsx, emd_bias_table_meta.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import wasserstein_distance\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ------------------------------\n",
        "# Configuration: set your file paths here\n",
        "# ------------------------------\n",
        "DATASETS = {\n",
        "    # D7 – Kaggle: Exploring Risk Factors for Cardiovascular Disease\n",
        "    # Columns in your upload: gender (1=Male, 2=Female), cardio (0/1)\n",
        "    \"D7\": {\n",
        "        \"path\": \"D7.csv\",\n",
        "        \"gender_col\": \"gender\",\n",
        "        \"label_col\": \"cardio\",\n",
        "        \"gender_map\": {1: 1, 2: 0},  # 1=Male->1, 2=Female->0\n",
        "    },\n",
        "\n",
        "    # D58 – Kaggle: Diabetes Health Indicators (BRFSS 2015)\n",
        "    # Typical columns: Sex (0=Female, 1=Male), Diabetes_binary (0/1)\n",
        "    \"D58\": {\n",
        "        \"path\": \"D58.csv\",\n",
        "        \"gender_col\": \"Sex\",\n",
        "        \"label_col\": \"Diabetes_binary\",\n",
        "        \"gender_map\": {0: 0, 1: 1},  # 0=Female->0, 1=Male->1\n",
        "    },\n",
        "\n",
        "    # D73 – UCI: Sepsis Survival minimal clinical records\n",
        "    # You set: sex_0male_1female (0=Male,1=Female), hospital_outcome_1alive_0dead (0/1)\n",
        "    \"D73\": {\n",
        "        \"path\": \"D73.csv\",\n",
        "        \"gender_col\": \"sex_0male_1female\",\n",
        "        \"label_col\": \"hospital_outcome_1alive_0dead\",\n",
        "        \"gender_map\": {0: 1, 1: 0},  # 0=Male->1, 1=Female->0\n",
        "    },\n",
        "}\n",
        "\n",
        "# ------------------------------\n",
        "# Helpers to detect/standardize columns\n",
        "# ------------------------------\n",
        "GENDER_CANDIDATES = [\"male\", \"sex\", \"gender\", \"Sex\", \"Gender\", \"Male\"]\n",
        "LABEL_CANDIDATES  = [\n",
        "    \"TenYearCHD\", \"tenyearchd\", \"target\", \"Target\", \"Outcome\", \"outcome\",\n",
        "    \"CHD\", \"label\", \"Label\", \"Survival\", \"survival\", \"DEATH_EVENT\", \"Diabetes_binary\",\n",
        "    \"diabetes_binary\", \"diabetes\", \"Diabetes\", \"SepsisLabel\", \"sepsislabel\", \"sepsis\"\n",
        "]\n",
        "\n",
        "STR_TRUE  = {\"1\",\"true\",\"yes\",\"y\",\"t\",\"pos\",\"positive\"}\n",
        "STR_MALE  = {\"male\",\"m\"}\n",
        "STR_FEMALE= {\"female\",\"f\"}\n",
        "\n",
        "def find_column(df: pd.DataFrame, candidates):\n",
        "    cols = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        if cand.lower() in cols:\n",
        "            return cols[cand.lower()]\n",
        "    return None\n",
        "\n",
        "def coerce_binary(series: pd.Series, positive_hint=None):\n",
        "    \"\"\"\n",
        "    Coerce a gender/label series into {0,1}.\n",
        "    For gender: returns (is_male: 1=male, 0=female).\n",
        "    For label: returns (is_positive: 1=positive, 0=negative).\n",
        "    \"\"\"\n",
        "    s = series.copy()\n",
        "\n",
        "    # If numeric 0/1 already:\n",
        "    if pd.api.types.is_numeric_dtype(s):\n",
        "        uniq = set(pd.unique(s.dropna()))\n",
        "        if uniq.issubset({0,1}):\n",
        "            return s.astype(int)\n",
        "\n",
        "    # String-like\n",
        "    s = s.astype(str).str.strip().str.lower()\n",
        "\n",
        "    if positive_hint == \"male\":\n",
        "        return s.apply(lambda v: 1 if v in STR_MALE or v == \"1\" else (0 if v in STR_FEMALE or v == \"0\" else np.nan)).astype(\"float\")\n",
        "    elif positive_hint == \"positive\":\n",
        "        return s.apply(lambda v: 1 if (v in STR_TRUE) else\n",
        "                              (0 if (v in {\"0\",\"neg\",\"negative\",\"no\",\"n\",\"false\",\"f\"}) else np.nan)).astype(\"float\")\n",
        "\n",
        "    # Heuristic: if values look like M/F or male/female\n",
        "    if s.isin(STR_MALE | STR_FEMALE).mean() > 0.5:\n",
        "        return s.apply(lambda v: 1 if v in STR_MALE else (0 if v in STR_FEMALE else np.nan)).astype(\"float\")\n",
        "\n",
        "    # Otherwise try numeric strings\n",
        "    return s.apply(lambda v: 1 if v in {\"1\"} else (0 if v in {\"0\"} else np.nan)).astype(\"float\")\n",
        "\n",
        "def infer_binary_label(df: pd.DataFrame, exclude_cols=set()):\n",
        "    \"\"\"\n",
        "    Attempt to find a binary label column (0/1) distinct from gender.\n",
        "    Preference: known candidates; otherwise any column with exactly two unique numeric values {0,1}.\n",
        "    \"\"\"\n",
        "    # Try candidate names first\n",
        "    for cand in LABEL_CANDIDATES:\n",
        "        col = find_column(df, [cand])\n",
        "        if col and col not in exclude_cols:\n",
        "            coerced = coerce_binary(df[col], positive_hint=\"positive\")\n",
        "            if set(pd.unique(coerced.dropna())).issubset({0.0,1.0}):\n",
        "                return col, coerced.astype(int)\n",
        "\n",
        "    # Fallback: scan columns\n",
        "    for col in df.columns:\n",
        "        if col in exclude_cols:\n",
        "            continue\n",
        "        ser = df[col]\n",
        "        if pd.api.types.is_numeric_dtype(ser):\n",
        "            uniq = set(pd.unique(ser.dropna()))\n",
        "            if uniq.issubset({0,1}) and len(uniq) == 2:\n",
        "                return col, ser.astype(int)\n",
        "\n",
        "        # try coercion\n",
        "        coerced = coerce_binary(ser, positive_hint=\"positive\")\n",
        "        uniq = set(pd.unique(coerced.dropna()))\n",
        "        if uniq.issubset({0.0,1.0}) and len(uniq) == 2:\n",
        "            return col, coerced.astype(int)\n",
        "\n",
        "    raise ValueError(\"Could not infer a binary label column; please set label_col explicitly in DATASETS.\")\n",
        "\n",
        "def get_gender_and_label(df: pd.DataFrame, gender_col=None, label_col=None, gender_map=None):\n",
        "    # Gender\n",
        "    gcol = gender_col or find_column(df, GENDER_CANDIDATES)\n",
        "    if gcol is None:\n",
        "        raise ValueError(\"Could not find a gender column; set 'gender_col' in DATASETS.\")\n",
        "\n",
        "    if gender_map is not None:\n",
        "        gender01 = df[gcol].map(gender_map)\n",
        "        if gender01.isna().any():\n",
        "            raise ValueError(f\"Gender mapping failed for column '{gcol}'. Check values and 'gender_map'.\")\n",
        "        gender01 = gender01.astype(int)\n",
        "    else:\n",
        "        gender = df[gcol]\n",
        "        gender01 = coerce_binary(gender, positive_hint=\"male\").astype(\"float\")\n",
        "        if gender01.isna().mean() > 0.3:\n",
        "            if pd.api.types.is_numeric_dtype(gender):\n",
        "                uniq = sorted(pd.unique(gender.dropna()))\n",
        "                if set(uniq).issubset({0,1}):\n",
        "                    gender01 = gender.astype(int)\n",
        "                elif set(uniq).issubset({1,2}):\n",
        "                    gender01 = gender.map({1:1, 2:0}).astype(int)\n",
        "                else:\n",
        "                    raise ValueError(f\"Gender column '{gcol}' could not be coerced to 0/1.\")\n",
        "            else:\n",
        "                raise ValueError(f\"Gender column '{gcol}' could not be coerced to 0/1.\")\n",
        "        else:\n",
        "            gender01 = gender01.astype(int)\n",
        "\n",
        "    # Label\n",
        "    if label_col:\n",
        "        lab = df[label_col]\n",
        "        lab01 = coerce_binary(lab, positive_hint=\"positive\").astype(\"float\")\n",
        "        if not set(pd.unique(lab01.dropna())).issubset({0.0,1.0}):\n",
        "            raise ValueError(f\"Label column '{label_col}' is not binary 0/1 after coercion.\")\n",
        "        lab01 = lab01.astype(int)\n",
        "        return gender01, lab01, gcol, label_col\n",
        "    else:\n",
        "        label_col_inferred, lab01 = infer_binary_label(df, exclude_cols={gcol})\n",
        "        return gender01, lab01, gcol, label_col_inferred\n",
        "\n",
        "# ------------------------------\n",
        "# EMD + bootstrap p-value\n",
        "# ------------------------------\n",
        "def compute_emd_pvalue_binary(all_labels01: np.ndarray,\n",
        "                              subgroup_labels01: np.ndarray,\n",
        "                              n_iter: int = 10000,\n",
        "                              seed: int = 42):\n",
        "    \"\"\"\n",
        "    Earth Mover's Distance between subgroup label distribution and overall label distribution.\n",
        "    Labels must be 0/1 (binary). Permutation bootstrap p-value.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    all_labels01 = all_labels01.astype(int)\n",
        "    subgroup_labels01 = subgroup_labels01.astype(int)\n",
        "\n",
        "    observed = wasserstein_distance(subgroup_labels01, all_labels01)\n",
        "\n",
        "    n = len(all_labels01)\n",
        "    k = len(subgroup_labels01)\n",
        "    boot = np.empty(n_iter, dtype=float)\n",
        "    for i in range(n_iter):\n",
        "        idx = rng.choice(n, size=k, replace=False)\n",
        "        boot[i] = wasserstein_distance(all_labels01[idx], all_labels01)\n",
        "\n",
        "    p_val = float((boot >= observed).mean())\n",
        "    return float(observed), p_val\n",
        "\n",
        "# ------------------------------\n",
        "# Main runner\n",
        "# ------------------------------\n",
        "def run_for_dataset(tag: str, cfg: dict, n_iter: int = 10000):\n",
        "    df = pd.read_csv(cfg[\"path\"])\n",
        "    df = df.dropna(axis=0, how=\"any\").reset_index(drop=True)\n",
        "\n",
        "    gender01, label01, gcol, lcol = get_gender_and_label(\n",
        "        df,\n",
        "        gender_col=cfg.get(\"gender_col\"),\n",
        "        label_col=cfg.get(\"label_col\"),\n",
        "        gender_map=cfg.get(\"gender_map\"),\n",
        "    )\n",
        "\n",
        "    # Masks\n",
        "    male_mask   = (gender01 == 1)\n",
        "    female_mask = (gender01 == 0)\n",
        "\n",
        "    all_labels    = label01\n",
        "    female_labels = label01[female_mask]\n",
        "    male_labels   = label01[male_mask]\n",
        "\n",
        "    fem_emd, fem_p = compute_emd_pvalue_binary(all_labels, female_labels, n_iter=n_iter)\n",
        "    mal_emd, mal_p = compute_emd_pvalue_binary(all_labels, male_labels,   n_iter=n_iter)\n",
        "\n",
        "    out = pd.DataFrame([\n",
        "        {\"Dataset\": tag, \"Group\": \"Female\", \"EMD value\": fem_emd, \"p-value\": fem_p,\n",
        "         \"Exhibit data bias?\": \"Yes\" if fem_p <= 0.05 else \"No\"},\n",
        "        {\"Dataset\": tag, \"Group\": \"Male\",   \"EMD value\": mal_emd, \"p-value\": mal_p,\n",
        "         \"Exhibit data bias?\": \"Yes\" if mal_p <= 0.05 else \"No\"},\n",
        "    ])\n",
        "    meta = {\"gender_col_used\": gcol, \"label_col_used\": lcol, \"N\": len(df),\n",
        "            \"N_female\": int(female_mask.sum()), \"N_male\": int(male_mask.sum())}\n",
        "    return out, meta\n",
        "\n",
        "def main(n_iter=10000):\n",
        "    tables = []\n",
        "    metas  = []\n",
        "    for tag, cfg in DATASETS.items():\n",
        "        print(f\"Processing {tag} ...\")\n",
        "        t, m = run_for_dataset(tag, cfg, n_iter=n_iter)\n",
        "        tables.append(t)\n",
        "        metas.append(pd.DataFrame([{\"Dataset\": tag, **m}]))\n",
        "\n",
        "    table = pd.concat(tables, ignore_index=True)\n",
        "    meta  = pd.concat(metas, ignore_index=True)\n",
        "\n",
        "    print(\"\\n=== EMD Bias Table ===\")\n",
        "    print(table.to_string(index=False))\n",
        "    print(\"\\n=== Detection Metadata (for reproducibility) ===\")\n",
        "    print(meta.to_string(index=False))\n",
        "\n",
        "    table.to_csv(\"emd_bias_table.csv\", index=False)\n",
        "    table.to_excel(\"emd_bias_table.xlsx\", index=False)\n",
        "    meta.to_csv(\"emd_bias_table_meta.csv\", index=False)\n",
        "    print(\"\\nSaved: emd_bias_table.csv, emd_bias_table.xlsx, emd_bias_table_meta.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # You can lower n_iter for a quick run (e.g., 2000) and increase later (e.g., 10000/50000)\n",
        "    main(n_iter=2000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import wilcoxon\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ===========================\n",
        "# Speed controls\n",
        "# ===========================\n",
        "FAST_MODE = True          # set True to speed up everything (folds, RF trees, etc.)\n",
        "FAST_SVM  = True          # set True to replace kernel SVM with fast linear (SGD/LinearSVC)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "N_SPLITS = 10\n",
        "P_THRESHOLD = 0.05\n",
        "\n",
        "VERBOSE = True\n",
        "PRINT_EVERY_FOLD = 1\n",
        "PRINT_MODEL_STEPS = True\n",
        "\n",
        "def log(msg):\n",
        "    if VERBOSE:\n",
        "        ts = time.strftime(\"%H:%M:%S\")\n",
        "        print(f\"[{ts}] {msg}\", flush=True, file=sys.stdout)\n",
        "\n",
        "# ===========================\n",
        "# CONFIG: dataset schemas\n",
        "# ===========================\n",
        "DATASETS = {\n",
        "    \"D7\": {\n",
        "        \"path\": \"D7.csv\",\n",
        "        \"gender_col\": \"gender\",                   # 1=Male, 2=Female\n",
        "        \"label_col\": \"cardio\",                    # 0/1\n",
        "        \"gender_map\": {1: 1, 2: 0},               # Male=1, Female=0\n",
        "    },\n",
        "    \"D58\": {\n",
        "        \"path\": \"D58.csv\",\n",
        "        \"gender_col\": \"Sex\",                      # 0=Female, 1=Male\n",
        "        \"label_col\": \"Diabetes_binary\",           # 0/1\n",
        "        \"gender_map\": {0: 0, 1: 1},\n",
        "    },\n",
        "    \"D73\": {\n",
        "        \"path\": \"D73.csv\",\n",
        "        \"gender_col\": \"sex_0male_1female\",        # 0=Male, 1=Female\n",
        "        \"label_col\": \"hospital_outcome_1alive_0dead\",  # 1=alive, 0=dead\n",
        "        \"gender_map\": {0: 1, 1: 0},               # Male=1, Female=0\n",
        "    },\n",
        "}\n",
        "\n",
        "# ===========================\n",
        "# Models\n",
        "# ===========================\n",
        "def get_models():\n",
        "    rf_estimators = 150 if FAST_MODE else 300\n",
        "    if FAST_SVM:\n",
        "        # Fast linear margin classifier standing in for SVM\n",
        "        # Option 1: SGDClassifier (very fast, supports decision_function)\n",
        "        svm_clf = Pipeline([\n",
        "            (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "            (\"clf\", SGDClassifier(\n",
        "                loss=\"hinge\",\n",
        "                alpha=1e-4,\n",
        "                max_iter=2000 if FAST_MODE else 4000,\n",
        "                tol=1e-3,\n",
        "                random_state=RANDOM_STATE\n",
        "            ))\n",
        "        ])\n",
        "        # Option 2: LinearSVC (also fast); uncomment to use instead of SGD\n",
        "        # svm_clf = Pipeline([\n",
        "        #     (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "        #     (\"clf\", LinearSVC(\n",
        "        #         C=1.0,\n",
        "        #         max_iter=5000 if FAST_MODE else 10000,\n",
        "        #         random_state=RANDOM_STATE\n",
        "        #     ))\n",
        "        # ])\n",
        "    else:\n",
        "        # Slower but classic SVM; keep probability=False to avoid Platt scaling\n",
        "        svm_clf = Pipeline([\n",
        "            (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "            (\"clf\", SVC(kernel=\"rbf\", probability=False, cache_size=1000, random_state=RANDOM_STATE))\n",
        "        ])\n",
        "\n",
        "    return {\n",
        "        \"LR\": Pipeline([\n",
        "            (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "            (\"clf\", LogisticRegression(max_iter=1000, n_jobs=None, random_state=RANDOM_STATE))\n",
        "        ]),\n",
        "        \"KNN\": Pipeline([\n",
        "            (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "            (\"clf\", KNeighborsClassifier(n_neighbors=5))\n",
        "        ]),\n",
        "        \"DT\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "        \"RF\": RandomForestClassifier(\n",
        "            n_estimators=rf_estimators,\n",
        "            max_depth=None,\n",
        "            n_jobs=-1,\n",
        "            random_state=RANDOM_STATE\n",
        "        ),\n",
        "        \"SVM\": svm_clf,\n",
        "    }\n",
        "\n",
        "# ===========================\n",
        "# Utilities\n",
        "# ===========================\n",
        "def fmt_p(p):\n",
        "    try:\n",
        "        if p is None or np.isnan(p) or p > P_THRESHOLD:\n",
        "            return \"…\"\n",
        "        return f\"{p:.4f}\"\n",
        "    except Exception:\n",
        "        return \"…\"\n",
        "\n",
        "def safe_div(a, b):\n",
        "    return np.nan if (b is None or b == 0) else (a / b)\n",
        "\n",
        "def confusion_by_group(y_true, y_pred, group_mask):\n",
        "    yt = y_true[group_mask]\n",
        "    yp = y_pred[group_mask]\n",
        "    if yt.size == 0:\n",
        "        return dict(TP=0, FP=0, TN=0, FN=0, TPR=np.nan, FPR=np.nan, FNR=np.nan, PPR=np.nan)\n",
        "    TP = int(((yp == 1) & (yt == 1)).sum())\n",
        "    FP = int(((yp == 1) & (yt == 0)).sum())\n",
        "    TN = int(((yp == 0) & (yt == 0)).sum())\n",
        "    FN = int(((yp == 0) & (yt == 1)).sum())\n",
        "    TPR = safe_div(TP, TP + FN)\n",
        "    FPR = safe_div(FP, FP + TN)\n",
        "    FNR = safe_div(FN, TP + FN)\n",
        "    PPR = safe_div((yp == 1).sum(), yp.size)\n",
        "    return dict(TP=TP, FP=FP, TN=TN, FN=FN, TPR=TPR, FPR=FPR, FNR=FNR, PPR=PPR)\n",
        "\n",
        "def score_by_group(y_score, group_mask):\n",
        "    ys = y_score[group_mask]\n",
        "    if ys.size == 0:\n",
        "        return np.nan\n",
        "    return float(np.mean(ys))\n",
        "\n",
        "def wilcoxon_paired_zero_center(diffs):\n",
        "    diffs = np.array(diffs, dtype=float)\n",
        "    diffs = diffs[~np.isnan(diffs)]\n",
        "    if diffs.size == 0:\n",
        "        return None\n",
        "    if np.allclose(diffs, 0.0):\n",
        "        return 1.0\n",
        "    try:\n",
        "        stat, p = wilcoxon(\n",
        "            diffs,\n",
        "            zero_method=\"wilcox\",\n",
        "            alternative=\"two-sided\",\n",
        "            correction=False,\n",
        "            mode=\"exact\" if diffs.size <= 25 else \"approx\"\n",
        "        )\n",
        "        return float(p)\n",
        "    except Exception:\n",
        "        try:\n",
        "            stat, p = wilcoxon(\n",
        "                diffs,\n",
        "                zero_method=\"wilcox\",\n",
        "                alternative=\"two-sided\",\n",
        "                correction=False,\n",
        "                mode=\"approx\"\n",
        "            )\n",
        "            return float(p)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "def prepare_xy(df, gender_col, label_col):\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    assert gender_col in df.columns and label_col in df.columns, \"Gender/label column not found.\"\n",
        "    feature_cols = [c for c in numeric_cols if c not in {gender_col, label_col}]\n",
        "    X = df[feature_cols].values\n",
        "    y = df[label_col].astype(int).values\n",
        "    g = df[gender_col].astype(int).values  # Male=1, Female=0\n",
        "    return X, y, g, feature_cols\n",
        "\n",
        "def load_dataset(cfg):\n",
        "    log(f\"Loading dataset from {cfg['path']}\")\n",
        "    df = pd.read_csv(cfg[\"path\"])\n",
        "    log(f\"Loaded shape: {df.shape}\")\n",
        "    if \"gender_map\" in cfg and cfg[\"gender_map\"] is not None:\n",
        "        log(f\"Applying gender map for column '{cfg['gender_col']}' -> Male=1, Female=0\")\n",
        "        df[cfg[\"gender_col\"]] = df[cfg[\"gender_col\"]].map(cfg[\"gender_map\"])\n",
        "    lab_min, lab_max = df[cfg[\"label_col\"]].min(), df[cfg[\"label_col\"]].max()\n",
        "    log(f\"Label column '{cfg['label_col']}' value range before coercion: [{lab_min}, {lab_max}]\")\n",
        "    df[cfg[\"label_col\"]] = (df[cfg[\"label_col\"]].astype(float) > 0).astype(int)\n",
        "    used = [cfg[\"gender_col\"], cfg[\"label_col\"]]\n",
        "    before = df.shape[0]\n",
        "    df = df.dropna(subset=used).copy()\n",
        "    after = df.shape[0]\n",
        "    log(f\"Dropped {before - after} rows due to NA in gender/label; remaining: {after}\")\n",
        "    before = df.shape[0]\n",
        "    df = df[df[cfg[\"gender_col\"]].isin([0, 1])]\n",
        "    df = df[df[cfg[\"label_col\"]].isin([0, 1])]\n",
        "    after = df.shape[0]\n",
        "    if after < before:\n",
        "        log(f\"Removed {before - after} rows due to non-binary gender/label; remaining: {after}\")\n",
        "    before = df.shape[0]\n",
        "    df = df.dropna(axis=0, how=\"any\")\n",
        "    after = df.shape[0]\n",
        "    if after < before:\n",
        "        log(f\"Dropped {before - after} rows due to NA in features; remaining: {after}\")\n",
        "    log(\"Dataset ready.\")\n",
        "    return df\n",
        "\n",
        "# ===========================\n",
        "# Fairness evaluation (per model, per dataset)\n",
        "# ===========================\n",
        "def evaluate_fairness_for_models(X, y, g, models):\n",
        "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
        "    results = {name: {\n",
        "        \"dp_diff\": [],\n",
        "        \"eo_tpr_diff\": [],\n",
        "        \"eo_fpr_diff\": [],\n",
        "        \"eopp_tpr_diff\": [],\n",
        "        \"fpr_par_diff\": [],\n",
        "        \"te_log_ratio_diff\": [],\n",
        "        \"ds_score_diff\": [],\n",
        "        \"di_log_ratio\": [],\n",
        "        \"ber_diff\": [],\n",
        "    } for name in models.keys()}\n",
        "\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
        "        if (fold - 1) % PRINT_EVERY_FOLD == 0:\n",
        "            log(f\"Starting fold {fold}/{N_SPLITS} (train n={len(train_idx)}, test n={len(test_idx)})\")\n",
        "\n",
        "        Xtr, Xte = X[train_idx], X[test_idx]\n",
        "        ytr, yte = y[train_idx], y[test_idx]\n",
        "        gtr, gte = g[train_idx], g[test_idx]\n",
        "\n",
        "        female_mask = (gte == 0)\n",
        "        male_mask   = (gte == 1)\n",
        "\n",
        "        for name, model in models.items():\n",
        "            if PRINT_MODEL_STEPS:\n",
        "                log(f\"  [{name}] fitting on fold {fold}\")\n",
        "            clf = model\n",
        "            clf.fit(Xtr, ytr)\n",
        "\n",
        "            if PRINT_MODEL_STEPS:\n",
        "                log(f\"  [{name}] predicting on fold {fold}\")\n",
        "            y_pred = clf.predict(Xte)\n",
        "\n",
        "            if hasattr(clf, \"predict_proba\"):\n",
        "                y_score = clf.predict_proba(Xte)[:, 1]\n",
        "            else:\n",
        "                if hasattr(clf, \"decision_function\"):\n",
        "                    dfun = clf.decision_function(Xte)\n",
        "                    mn, mx = np.min(dfun), np.max(dfun)\n",
        "                    y_score = (dfun - mn) / (mx - mn + 1e-12)\n",
        "                else:\n",
        "                    y_score = y_pred.astype(float)\n",
        "\n",
        "            gf = confusion_by_group(yte, y_pred, female_mask)\n",
        "            gm = confusion_by_group(yte, y_pred, male_mask)\n",
        "\n",
        "            ppr_f, ppr_m = gf[\"PPR\"], gm[\"PPR\"]\n",
        "            tpr_f, tpr_m = gf[\"TPR\"], gm[\"TPR\"]\n",
        "            fpr_f, fpr_m = gf[\"FPR\"], gm[\"FPR\"]\n",
        "            fnr_f, fnr_m = gf[\"FNR\"], gm[\"FNR\"]\n",
        "\n",
        "            eopp_diff = (tpr_f - tpr_m) if (not np.isnan(tpr_f) and not np.isnan(tpr_m)) else np.nan\n",
        "            ratio_f = safe_div(fnr_f, fpr_f) if (not np.isnan(fnr_f) and not np.isnan(fpr_f)) else np.nan\n",
        "            ratio_m = safe_div(fnr_m, fpr_m) if (not np.isnan(fnr_m) and not np.isnan(fpr_m)) else np.nan\n",
        "            te_log_ratio_diff = np.nan\n",
        "            if not np.isnan(ratio_f) and not np.isnan(ratio_m) and ratio_f and ratio_m:\n",
        "                te_log_ratio_diff = np.log(ratio_f + 1e-12) - np.log(ratio_m + 1e-12)\n",
        "\n",
        "            ds_diff = score_by_group(y_score, female_mask) - score_by_group(y_score, male_mask)\n",
        "            di_lr = np.nan\n",
        "            if not np.isnan(ppr_f) and not np.isnan(ppr_m) and ppr_f and ppr_m:\n",
        "                di_lr = np.log((ppr_f + 1e-12) / (ppr_m + 1e-12))\n",
        "\n",
        "            ber_f = np.nanmean([fnr_f, fpr_f])\n",
        "            ber_m = np.nanmean([fnr_m, fpr_m])\n",
        "            ber_diff = ber_f - ber_m if (not np.isnan(ber_f) and not np.isnan(ber_m)) else np.nan\n",
        "\n",
        "            results[name][\"dp_diff\"].append((ppr_f - ppr_m) if (not np.isnan(ppr_f) and not np.isnan(ppr_m)) else np.nan)\n",
        "            results[name][\"eo_tpr_diff\"].append((tpr_f - tpr_m) if (not np.isnan(tpr_f) and not np.isnan(tpr_m)) else np.nan)\n",
        "            results[name][\"eo_fpr_diff\"].append((fpr_f - fpr_m) if (not np.isnan(fpr_f) and not np.isnan(fpr_m)) else np.nan)\n",
        "            results[name][\"eopp_tpr_diff\"].append(eopp_diff)\n",
        "            results[name][\"fpr_par_diff\"].append((fpr_f - fpr_m) if (not np.isnan(fpr_f) and not np.isnan(fpr_m)) else np.nan)\n",
        "            results[name][\"te_log_ratio_diff\"].append(te_log_ratio_diff)\n",
        "            results[name][\"ds_score_diff\"].append(ds_diff)\n",
        "            results[name][\"di_log_ratio\"].append(di_lr)\n",
        "            results[name][\"ber_diff\"].append(ber_diff)\n",
        "\n",
        "        if (fold - 1) % PRINT_EVERY_FOLD == 0:\n",
        "            log(f\"Completed fold {fold}/{N_SPLITS}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def pvalues_from_results(results):\n",
        "    out = {}\n",
        "    for name, vals in results.items():\n",
        "        log(f\"Computing Wilcoxon p-values for model {name}\")\n",
        "        dp_p     = wilcoxon_paired_zero_center(vals[\"dp_diff\"])\n",
        "        eo_tpr_p = wilcoxon_paired_zero_center(vals[\"eo_tpr_diff\"])\n",
        "        eo_fpr_p = wilcoxon_paired_zero_center(vals[\"eo_fpr_diff\"])\n",
        "        eopp_p   = wilcoxon_paired_zero_center(vals[\"eopp_tpr_diff\"])\n",
        "        fpr_p    = wilcoxon_paired_zero_center(vals[\"fpr_par_diff\"])\n",
        "        te_p     = wilcoxon_paired_zero_center(vals[\"te_log_ratio_diff\"])\n",
        "        ds_p     = wilcoxon_paired_zero_center(vals[\"ds_score_diff\"])\n",
        "        di_p     = wilcoxon_paired_zero_center(vals[\"di_log_ratio\"])\n",
        "        ber_p    = wilcoxon_paired_zero_center(vals[\"ber_diff\"])\n",
        "\n",
        "        out[name] = {\n",
        "            \"Demographic parity\": fmt_p(dp_p),\n",
        "            \"Equalised odds\": f\"TPR={fmt_p(eo_tpr_p)}, FPR={fmt_p(eo_fpr_p)}\",\n",
        "            \"Equal opportunity\": fmt_p(eopp_p),\n",
        "            \"False positive rate parity\": fmt_p(fpr_p),\n",
        "            \"Treatment equality\": fmt_p(te_p),\n",
        "            \"Discrimination score\": fmt_p(ds_p),\n",
        "            \"Disparate Impact\": fmt_p(di_p),\n",
        "            \"Balanced Error Rate\": fmt_p(ber_p),\n",
        "        }\n",
        "    return out\n",
        "\n",
        "def build_table(pvalues_map):\n",
        "    fairness_rows = [\n",
        "        \"Demographic parity\",\n",
        "        \"Equalised odds\",\n",
        "        \"Equal opportunity\",\n",
        "        \"False positive rate parity\",\n",
        "        \"Treatment equality\",\n",
        "        \"Discrimination score\",\n",
        "        \"Disparate Impact\",\n",
        "        \"Balanced Error Rate\",\n",
        "    ]\n",
        "    model_names = list(pvalues_map.keys())\n",
        "    data = {m: [pvalues_map[m][row] for row in fairness_rows] for m in model_names}\n",
        "    return pd.DataFrame(data, index=fairness_rows)\n",
        "\n",
        "# ===========================\n",
        "# Orchestrator\n",
        "# ===========================\n",
        "def run_for_dataset(tag, cfg):\n",
        "    log(f\"=== Processing {tag} ===\")\n",
        "    df = load_dataset(cfg)\n",
        "    log(\"Preparing X, y, g matrices\")\n",
        "    X, y, g, feature_cols = prepare_xy(df, cfg[\"gender_col\"], cfg[\"label_col\"])\n",
        "    log(f\"Feature matrix shape: {X.shape}, labels shape: {y.shape}, gender shape: {g.shape}\")\n",
        "    models = get_models()\n",
        "    log(f\"Evaluating fairness across {len(models)} models with {N_SPLITS}-fold CV (FAST_MODE={FAST_MODE}, FAST_SVM={FAST_SVM})\")\n",
        "    results = evaluate_fairness_for_models(X, y, g, models)\n",
        "    log(\"Aggregating per-fold differences into Wilcoxon tests\")\n",
        "    pvals = pvalues_from_results(results)\n",
        "    table = build_table(pvals)\n",
        "    log(\"Final table for this dataset:\")\n",
        "    log(\"\\n\" + table.to_string())\n",
        "    out_csv = f\"fairness_table_{tag}.csv\"\n",
        "    out_xlsx = f\"fairness_table_{tag}.xlsx\"\n",
        "    table.to_csv(out_csv)\n",
        "    log(f\"Saved {out_csv}\")\n",
        "    try:\n",
        "        table.to_excel(out_xlsx)\n",
        "        log(f\"Saved {out_xlsx}\")\n",
        "    except Exception as e:\n",
        "        log(f\"Could not save Excel for {tag}: {e}\")\n",
        "    log(f\"=== Done {tag} ===\")\n",
        "    return table\n",
        "\n",
        "def main():\n",
        "    log(\"Starting fairness evaluation for all datasets\")\n",
        "    tables = {}\n",
        "    for i, (tag, cfg) in enumerate(DATASETS.items(), start=1):\n",
        "        log(f\"Dataset {i}/{len(DATASETS)}: {tag}\")\n",
        "        tables[tag] = run_for_dataset(tag, cfg)\n",
        "    try:\n",
        "        log(\"Writing combined multi-sheet Excel: fairness_tables_all.xlsx\")\n",
        "        with pd.ExcelWriter(\"fairness_tables_all.xlsx\", engine=\"xlsxwriter\") as writer:\n",
        "            for tag, tbl in tables.items():\n",
        "                tbl.to_excel(writer, sheet_name=tag)\n",
        "        log(\"Saved fairness_tables_all.xlsx\")\n",
        "    except Exception as e:\n",
        "        log(f\"Could not write combined Excel: {e}\")\n",
        "    log(\"All done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUzh0ZHe4RuK",
        "outputId": "c1784c67-a636-4601-98aa-1d65420fa971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:30:59] Starting fairness evaluation for all datasets\n",
            "[07:30:59] Dataset 1/3: D7\n",
            "[07:30:59] === Processing D7 ===\n",
            "[07:30:59] Loading dataset from D7.csv\n",
            "[07:30:59] Loaded shape: (70000, 14)\n",
            "[07:30:59] Applying gender map for column 'gender' -> Male=1, Female=0\n",
            "[07:30:59] Label column 'cardio' value range before coercion: [0, 1]\n",
            "[07:30:59] Dropped 0 rows due to NA in gender/label; remaining: 70000\n",
            "[07:30:59] Dataset ready.\n",
            "[07:30:59] Preparing X, y, g matrices\n",
            "[07:30:59] Feature matrix shape: (70000, 12), labels shape: (70000,), gender shape: (70000,)\n",
            "[07:30:59] Evaluating fairness across 5 models with 10-fold CV (FAST_MODE=True, FAST_SVM=True)\n",
            "[07:30:59] Starting fold 1/10 (train n=63000, test n=7000)\n",
            "[07:30:59]   [LR] fitting on fold 1\n",
            "[07:31:00]   [LR] predicting on fold 1\n",
            "[07:31:00]   [KNN] fitting on fold 1\n",
            "[07:31:00]   [KNN] predicting on fold 1\n",
            "[07:31:11]   [DT] fitting on fold 1\n",
            "[07:31:12]   [DT] predicting on fold 1\n",
            "[07:31:12]   [RF] fitting on fold 1\n",
            "[07:31:32]   [RF] predicting on fold 1\n",
            "[07:31:32]   [SVM] fitting on fold 1\n",
            "[07:31:33]   [SVM] predicting on fold 1\n",
            "[07:31:33] Completed fold 1/10\n",
            "[07:31:33] Starting fold 2/10 (train n=63000, test n=7000)\n",
            "[07:31:33]   [LR] fitting on fold 2\n",
            "[07:31:33]   [LR] predicting on fold 2\n",
            "[07:31:33]   [KNN] fitting on fold 2\n",
            "[07:31:33]   [KNN] predicting on fold 2\n",
            "[07:31:38]   [DT] fitting on fold 2\n",
            "[07:31:39]   [DT] predicting on fold 2\n",
            "[07:31:39]   [RF] fitting on fold 2\n",
            "[07:31:59]   [RF] predicting on fold 2\n",
            "[07:31:59]   [SVM] fitting on fold 2\n",
            "[07:32:00]   [SVM] predicting on fold 2\n",
            "[07:32:00] Completed fold 2/10\n",
            "[07:32:00] Starting fold 3/10 (train n=63000, test n=7000)\n",
            "[07:32:00]   [LR] fitting on fold 3\n",
            "[07:32:00]   [LR] predicting on fold 3\n",
            "[07:32:00]   [KNN] fitting on fold 3\n",
            "[07:32:00]   [KNN] predicting on fold 3\n",
            "[07:32:06]   [DT] fitting on fold 3\n",
            "[07:32:07]   [DT] predicting on fold 3\n",
            "[07:32:07]   [RF] fitting on fold 3\n",
            "[07:32:27]   [RF] predicting on fold 3\n",
            "[07:32:27]   [SVM] fitting on fold 3\n",
            "[07:32:27]   [SVM] predicting on fold 3\n",
            "[07:32:27] Completed fold 3/10\n",
            "[07:32:27] Starting fold 4/10 (train n=63000, test n=7000)\n",
            "[07:32:27]   [LR] fitting on fold 4\n",
            "[07:32:28]   [LR] predicting on fold 4\n",
            "[07:32:28]   [KNN] fitting on fold 4\n",
            "[07:32:28]   [KNN] predicting on fold 4\n",
            "[07:32:33]   [DT] fitting on fold 4\n",
            "[07:32:34]   [DT] predicting on fold 4\n",
            "[07:32:34]   [RF] fitting on fold 4\n",
            "[07:32:53]   [RF] predicting on fold 4\n",
            "[07:32:54]   [SVM] fitting on fold 4\n",
            "[07:32:54]   [SVM] predicting on fold 4\n",
            "[07:32:54] Completed fold 4/10\n",
            "[07:32:54] Starting fold 5/10 (train n=63000, test n=7000)\n",
            "[07:32:54]   [LR] fitting on fold 5\n",
            "[07:32:55]   [LR] predicting on fold 5\n",
            "[07:32:55]   [KNN] fitting on fold 5\n",
            "[07:32:55]   [KNN] predicting on fold 5\n",
            "[07:33:00]   [DT] fitting on fold 5\n",
            "[07:33:01]   [DT] predicting on fold 5\n",
            "[07:33:01]   [RF] fitting on fold 5\n",
            "[07:33:21]   [RF] predicting on fold 5\n",
            "[07:33:21]   [SVM] fitting on fold 5\n",
            "[07:33:22]   [SVM] predicting on fold 5\n",
            "[07:33:22] Completed fold 5/10\n",
            "[07:33:22] Starting fold 6/10 (train n=63000, test n=7000)\n",
            "[07:33:22]   [LR] fitting on fold 6\n",
            "[07:33:22]   [LR] predicting on fold 6\n",
            "[07:33:22]   [KNN] fitting on fold 6\n",
            "[07:33:22]   [KNN] predicting on fold 6\n",
            "[07:33:27]   [DT] fitting on fold 6\n",
            "[07:33:28]   [DT] predicting on fold 6\n",
            "[07:33:29]   [RF] fitting on fold 6\n",
            "[07:33:48]   [RF] predicting on fold 6\n",
            "[07:33:48]   [SVM] fitting on fold 6\n",
            "[07:33:49]   [SVM] predicting on fold 6\n",
            "[07:33:49] Completed fold 6/10\n",
            "[07:33:49] Starting fold 7/10 (train n=63000, test n=7000)\n",
            "[07:33:49]   [LR] fitting on fold 7\n",
            "[07:33:49]   [LR] predicting on fold 7\n",
            "[07:33:49]   [KNN] fitting on fold 7\n",
            "[07:33:49]   [KNN] predicting on fold 7\n",
            "[07:33:55]   [DT] fitting on fold 7\n",
            "[07:33:56]   [DT] predicting on fold 7\n",
            "[07:33:56]   [RF] fitting on fold 7\n",
            "[07:34:15]   [RF] predicting on fold 7\n",
            "[07:34:15]   [SVM] fitting on fold 7\n",
            "[07:34:16]   [SVM] predicting on fold 7\n",
            "[07:34:16] Completed fold 7/10\n",
            "[07:34:16] Starting fold 8/10 (train n=63000, test n=7000)\n",
            "[07:34:16]   [LR] fitting on fold 8\n",
            "[07:34:16]   [LR] predicting on fold 8\n",
            "[07:34:16]   [KNN] fitting on fold 8\n",
            "[07:34:16]   [KNN] predicting on fold 8\n",
            "[07:34:23]   [DT] fitting on fold 8\n",
            "[07:34:24]   [DT] predicting on fold 8\n",
            "[07:34:24]   [RF] fitting on fold 8\n",
            "[07:34:42]   [RF] predicting on fold 8\n",
            "[07:34:43]   [SVM] fitting on fold 8\n",
            "[07:34:43]   [SVM] predicting on fold 8\n",
            "[07:34:43] Completed fold 8/10\n",
            "[07:34:43] Starting fold 9/10 (train n=63000, test n=7000)\n",
            "[07:34:43]   [LR] fitting on fold 9\n",
            "[07:34:43]   [LR] predicting on fold 9\n",
            "[07:34:43]   [KNN] fitting on fold 9\n",
            "[07:34:43]   [KNN] predicting on fold 9\n",
            "[07:34:50]   [DT] fitting on fold 9\n",
            "[07:34:51]   [DT] predicting on fold 9\n",
            "[07:34:51]   [RF] fitting on fold 9\n",
            "[07:35:09]   [RF] predicting on fold 9\n",
            "[07:35:10]   [SVM] fitting on fold 9\n",
            "[07:35:10]   [SVM] predicting on fold 9\n",
            "[07:35:10] Completed fold 9/10\n",
            "[07:35:10] Starting fold 10/10 (train n=63000, test n=7000)\n",
            "[07:35:10]   [LR] fitting on fold 10\n",
            "[07:35:10]   [LR] predicting on fold 10\n",
            "[07:35:10]   [KNN] fitting on fold 10\n",
            "[07:35:11]   [KNN] predicting on fold 10\n",
            "[07:35:17]   [DT] fitting on fold 10\n",
            "[07:35:18]   [DT] predicting on fold 10\n",
            "[07:35:18]   [RF] fitting on fold 10\n",
            "[07:35:36]   [RF] predicting on fold 10\n",
            "[07:35:37]   [SVM] fitting on fold 10\n",
            "[07:35:37]   [SVM] predicting on fold 10\n",
            "[07:35:37] Completed fold 10/10\n",
            "[07:35:37] Aggregating per-fold differences into Wilcoxon tests\n",
            "[07:35:37] Computing Wilcoxon p-values for model LR\n",
            "[07:35:37] Computing Wilcoxon p-values for model KNN\n",
            "[07:35:37] Computing Wilcoxon p-values for model DT\n",
            "[07:35:37] Computing Wilcoxon p-values for model RF\n",
            "[07:35:37] Computing Wilcoxon p-values for model SVM\n",
            "[07:35:37] Final table for this dataset:\n",
            "[07:35:37] \n",
            "                                      LR                     KNN                 DT                      RF                SVM\n",
            "Demographic parity                0.0371                       …             0.0039                  0.0098             0.0488\n",
            "Equalised odds              TPR=…, FPR=…  TPR=0.0273, FPR=0.0371  TPR=…, FPR=0.0371  TPR=0.0371, FPR=0.0059  TPR=…, FPR=0.0137\n",
            "Equal opportunity                      …                  0.0273                  …                  0.0371                  …\n",
            "False positive rate parity             …                  0.0371             0.0371                  0.0059             0.0137\n",
            "Treatment equality                     …                       …             0.0039                  0.0098             0.0371\n",
            "Discrimination score              0.0039                       …             0.0039                  0.0020                  …\n",
            "Disparate Impact                  0.0371                       …             0.0039                  0.0098             0.0488\n",
            "Balanced Error Rate                    …                  0.0098                  …                       …                  …\n",
            "[07:35:37] Saved fairness_table_D7.csv\n",
            "[07:35:37] Saved fairness_table_D7.xlsx\n",
            "[07:35:37] === Done D7 ===\n",
            "[07:35:37] Dataset 2/3: D58\n",
            "[07:35:37] === Processing D58 ===\n",
            "[07:35:37] Loading dataset from D58.csv\n",
            "[07:35:38] Loaded shape: (236378, 22)\n",
            "[07:35:38] Applying gender map for column 'Sex' -> Male=1, Female=0\n",
            "[07:35:38] Label column 'Diabetes_binary' value range before coercion: [0.0, 1.0]\n",
            "[07:35:38] Dropped 0 rows due to NA in gender/label; remaining: 236378\n",
            "[07:35:38] Dataset ready.\n",
            "[07:35:38] Preparing X, y, g matrices\n",
            "[07:35:38] Feature matrix shape: (236378, 20), labels shape: (236378,), gender shape: (236378,)\n",
            "[07:35:38] Evaluating fairness across 5 models with 10-fold CV (FAST_MODE=True, FAST_SVM=True)\n",
            "[07:35:38] Starting fold 1/10 (train n=212740, test n=23638)\n",
            "[07:35:38]   [LR] fitting on fold 1\n",
            "[07:35:39]   [LR] predicting on fold 1\n",
            "[07:35:39]   [KNN] fitting on fold 1\n",
            "[07:35:39]   [KNN] predicting on fold 1\n",
            "[07:36:36]   [DT] fitting on fold 1\n",
            "[07:36:37]   [DT] predicting on fold 1\n",
            "[07:36:37]   [RF] fitting on fold 1\n",
            "[07:37:12]   [RF] predicting on fold 1\n",
            "[07:37:14]   [SVM] fitting on fold 1\n",
            "[07:37:15]   [SVM] predicting on fold 1\n",
            "[07:37:15] Completed fold 1/10\n",
            "[07:37:15] Starting fold 2/10 (train n=212740, test n=23638)\n",
            "[07:37:15]   [LR] fitting on fold 2\n",
            "[07:37:16]   [LR] predicting on fold 2\n",
            "[07:37:16]   [KNN] fitting on fold 2\n",
            "[07:37:16]   [KNN] predicting on fold 2\n",
            "[07:38:13]   [DT] fitting on fold 2\n",
            "[07:38:15]   [DT] predicting on fold 2\n",
            "[07:38:15]   [RF] fitting on fold 2\n",
            "[07:38:52]   [RF] predicting on fold 2\n",
            "[07:38:54]   [SVM] fitting on fold 2\n",
            "[07:38:55]   [SVM] predicting on fold 2\n",
            "[07:38:55] Completed fold 2/10\n",
            "[07:38:55] Starting fold 3/10 (train n=212740, test n=23638)\n",
            "[07:38:55]   [LR] fitting on fold 3\n",
            "[07:38:55]   [LR] predicting on fold 3\n",
            "[07:38:55]   [KNN] fitting on fold 3\n",
            "[07:38:55]   [KNN] predicting on fold 3\n",
            "[07:39:54]   [DT] fitting on fold 3\n",
            "[07:39:55]   [DT] predicting on fold 3\n",
            "[07:39:55]   [RF] fitting on fold 3\n",
            "[07:40:30]   [RF] predicting on fold 3\n",
            "[07:40:33]   [SVM] fitting on fold 3\n",
            "[07:40:34]   [SVM] predicting on fold 3\n",
            "[07:40:34] Completed fold 3/10\n",
            "[07:40:34] Starting fold 4/10 (train n=212740, test n=23638)\n",
            "[07:40:34]   [LR] fitting on fold 4\n",
            "[07:40:34]   [LR] predicting on fold 4\n",
            "[07:40:35]   [KNN] fitting on fold 4\n",
            "[07:40:35]   [KNN] predicting on fold 4\n",
            "[07:41:31]   [DT] fitting on fold 4\n",
            "[07:41:32]   [DT] predicting on fold 4\n",
            "[07:41:32]   [RF] fitting on fold 4\n",
            "[07:42:09]   [RF] predicting on fold 4\n",
            "[07:42:11]   [SVM] fitting on fold 4\n",
            "[07:42:12]   [SVM] predicting on fold 4\n",
            "[07:42:12] Completed fold 4/10\n",
            "[07:42:12] Starting fold 5/10 (train n=212740, test n=23638)\n",
            "[07:42:12]   [LR] fitting on fold 5\n",
            "[07:42:13]   [LR] predicting on fold 5\n",
            "[07:42:13]   [KNN] fitting on fold 5\n",
            "[07:42:13]   [KNN] predicting on fold 5\n",
            "[07:43:11]   [DT] fitting on fold 5\n",
            "[07:43:12]   [DT] predicting on fold 5\n",
            "[07:43:12]   [RF] fitting on fold 5\n",
            "[07:43:52]   [RF] predicting on fold 5\n",
            "[07:43:54]   [SVM] fitting on fold 5\n",
            "[07:43:55]   [SVM] predicting on fold 5\n",
            "[07:43:55] Completed fold 5/10\n",
            "[07:43:55] Starting fold 6/10 (train n=212740, test n=23638)\n",
            "[07:43:55]   [LR] fitting on fold 6\n",
            "[07:43:56]   [LR] predicting on fold 6\n",
            "[07:43:56]   [KNN] fitting on fold 6\n",
            "[07:43:56]   [KNN] predicting on fold 6\n",
            "[07:44:53]   [DT] fitting on fold 6\n",
            "[07:44:54]   [DT] predicting on fold 6\n",
            "[07:44:54]   [RF] fitting on fold 6\n",
            "[07:45:34]   [RF] predicting on fold 6\n",
            "[07:45:35]   [SVM] fitting on fold 6\n",
            "[07:45:36]   [SVM] predicting on fold 6\n",
            "[07:45:36] Completed fold 6/10\n",
            "[07:45:36] Starting fold 7/10 (train n=212740, test n=23638)\n",
            "[07:45:36]   [LR] fitting on fold 7\n",
            "[07:45:37]   [LR] predicting on fold 7\n",
            "[07:45:37]   [KNN] fitting on fold 7\n",
            "[07:45:37]   [KNN] predicting on fold 7\n",
            "[07:46:35]   [DT] fitting on fold 7\n",
            "[07:46:36]   [DT] predicting on fold 7\n",
            "[07:46:36]   [RF] fitting on fold 7\n",
            "[07:47:10]   [RF] predicting on fold 7\n",
            "[07:47:12]   [SVM] fitting on fold 7\n",
            "[07:47:13]   [SVM] predicting on fold 7\n",
            "[07:47:13] Completed fold 7/10\n",
            "[07:47:13] Starting fold 8/10 (train n=212740, test n=23638)\n",
            "[07:47:13]   [LR] fitting on fold 8\n",
            "[07:47:14]   [LR] predicting on fold 8\n",
            "[07:47:14]   [KNN] fitting on fold 8\n",
            "[07:47:14]   [KNN] predicting on fold 8\n",
            "[07:48:12]   [DT] fitting on fold 8\n",
            "[07:48:13]   [DT] predicting on fold 8\n",
            "[07:48:13]   [RF] fitting on fold 8\n",
            "[07:48:48]   [RF] predicting on fold 8\n",
            "[07:48:51]   [SVM] fitting on fold 8\n",
            "[07:48:52]   [SVM] predicting on fold 8\n",
            "[07:48:52] Completed fold 8/10\n",
            "[07:48:52] Starting fold 9/10 (train n=212741, test n=23637)\n",
            "[07:48:52]   [LR] fitting on fold 9\n",
            "[07:48:53]   [LR] predicting on fold 9\n",
            "[07:48:53]   [KNN] fitting on fold 9\n",
            "[07:48:53]   [KNN] predicting on fold 9\n",
            "[07:49:50]   [DT] fitting on fold 9\n",
            "[07:49:51]   [DT] predicting on fold 9\n",
            "[07:49:51]   [RF] fitting on fold 9\n",
            "[07:50:31]   [RF] predicting on fold 9\n",
            "[07:50:34]   [SVM] fitting on fold 9\n",
            "[07:50:35]   [SVM] predicting on fold 9\n",
            "[07:50:35] Completed fold 9/10\n",
            "[07:50:35] Starting fold 10/10 (train n=212741, test n=23637)\n",
            "[07:50:35]   [LR] fitting on fold 10\n",
            "[07:50:36]   [LR] predicting on fold 10\n",
            "[07:50:36]   [KNN] fitting on fold 10\n",
            "[07:50:36]   [KNN] predicting on fold 10\n",
            "[07:51:32]   [DT] fitting on fold 10\n",
            "[07:51:33]   [DT] predicting on fold 10\n",
            "[07:51:33]   [RF] fitting on fold 10\n",
            "[07:52:11]   [RF] predicting on fold 10\n",
            "[07:52:13]   [SVM] fitting on fold 10\n",
            "[07:52:14]   [SVM] predicting on fold 10\n",
            "[07:52:14] Completed fold 10/10\n",
            "[07:52:14] Aggregating per-fold differences into Wilcoxon tests\n",
            "[07:52:14] Computing Wilcoxon p-values for model LR\n",
            "[07:52:14] Computing Wilcoxon p-values for model KNN\n",
            "[07:52:14] Computing Wilcoxon p-values for model DT\n",
            "[07:52:14] Computing Wilcoxon p-values for model RF\n",
            "[07:52:14] Computing Wilcoxon p-values for model SVM\n",
            "[07:52:14] Final table for this dataset:\n",
            "[07:52:14] \n",
            "                                                LR                KNN                 DT                 RF           SVM\n",
            "Demographic parity                          0.0020                  …             0.0273                  …             …\n",
            "Equalised odds              TPR=0.0039, FPR=0.0020  TPR=0.0020, FPR=…  TPR=0.0098, FPR=…  TPR=0.0137, FPR=…  TPR=…, FPR=…\n",
            "Equal opportunity                           0.0039             0.0020             0.0098             0.0137             …\n",
            "False positive rate parity                  0.0020                  …                  …                  …             …\n",
            "Treatment equality                          0.0020             0.0137                  …                  …             …\n",
            "Discrimination score                             …                  …             0.0098             0.0098             …\n",
            "Disparate Impact                            0.0020                  …             0.0273                  …             …\n",
            "Balanced Error Rate                         0.0039             0.0020             0.0059             0.0098             …\n",
            "[07:52:14] Saved fairness_table_D58.csv\n",
            "[07:52:14] Saved fairness_table_D58.xlsx\n",
            "[07:52:14] === Done D58 ===\n",
            "[07:52:14] Dataset 3/3: D73\n",
            "[07:52:14] === Processing D73 ===\n",
            "[07:52:14] Loading dataset from D73.csv\n",
            "[07:52:14] Loaded shape: (19051, 4)\n",
            "[07:52:14] Applying gender map for column 'sex_0male_1female' -> Male=1, Female=0\n",
            "[07:52:14] Label column 'hospital_outcome_1alive_0dead' value range before coercion: [0, 1]\n",
            "[07:52:14] Dropped 0 rows due to NA in gender/label; remaining: 19051\n",
            "[07:52:14] Dataset ready.\n",
            "[07:52:14] Preparing X, y, g matrices\n",
            "[07:52:14] Feature matrix shape: (19051, 2), labels shape: (19051,), gender shape: (19051,)\n",
            "[07:52:14] Evaluating fairness across 5 models with 10-fold CV (FAST_MODE=True, FAST_SVM=True)\n",
            "[07:52:14] Starting fold 1/10 (train n=17145, test n=1906)\n",
            "[07:52:14]   [LR] fitting on fold 1\n",
            "[07:52:14]   [LR] predicting on fold 1\n",
            "[07:52:14]   [KNN] fitting on fold 1\n",
            "[07:52:14]   [KNN] predicting on fold 1\n",
            "[07:52:14]   [DT] fitting on fold 1\n",
            "[07:52:14]   [DT] predicting on fold 1\n",
            "[07:52:14]   [RF] fitting on fold 1\n",
            "[07:52:16]   [RF] predicting on fold 1\n",
            "[07:52:16]   [SVM] fitting on fold 1\n",
            "[07:52:16]   [SVM] predicting on fold 1\n",
            "[07:52:16] Completed fold 1/10\n",
            "[07:52:16] Starting fold 2/10 (train n=17146, test n=1905)\n",
            "[07:52:16]   [LR] fitting on fold 2\n",
            "[07:52:16]   [LR] predicting on fold 2\n",
            "[07:52:16]   [KNN] fitting on fold 2\n",
            "[07:52:16]   [KNN] predicting on fold 2\n",
            "[07:52:16]   [DT] fitting on fold 2\n",
            "[07:52:16]   [DT] predicting on fold 2\n",
            "[07:52:16]   [RF] fitting on fold 2\n",
            "[07:52:17]   [RF] predicting on fold 2\n",
            "[07:52:17]   [SVM] fitting on fold 2\n",
            "[07:52:17]   [SVM] predicting on fold 2\n",
            "[07:52:17] Completed fold 2/10\n",
            "[07:52:17] Starting fold 3/10 (train n=17146, test n=1905)\n",
            "[07:52:17]   [LR] fitting on fold 3\n",
            "[07:52:17]   [LR] predicting on fold 3\n",
            "[07:52:17]   [KNN] fitting on fold 3\n",
            "[07:52:17]   [KNN] predicting on fold 3\n",
            "[07:52:17]   [DT] fitting on fold 3\n",
            "[07:52:17]   [DT] predicting on fold 3\n",
            "[07:52:17]   [RF] fitting on fold 3\n",
            "[07:52:18]   [RF] predicting on fold 3\n",
            "[07:52:18]   [SVM] fitting on fold 3\n",
            "[07:52:18]   [SVM] predicting on fold 3\n",
            "[07:52:18] Completed fold 3/10\n",
            "[07:52:18] Starting fold 4/10 (train n=17146, test n=1905)\n",
            "[07:52:18]   [LR] fitting on fold 4\n",
            "[07:52:18]   [LR] predicting on fold 4\n",
            "[07:52:18]   [KNN] fitting on fold 4\n",
            "[07:52:18]   [KNN] predicting on fold 4\n",
            "[07:52:18]   [DT] fitting on fold 4\n",
            "[07:52:18]   [DT] predicting on fold 4\n",
            "[07:52:18]   [RF] fitting on fold 4\n",
            "[07:52:19]   [RF] predicting on fold 4\n",
            "[07:52:19]   [SVM] fitting on fold 4\n",
            "[07:52:19]   [SVM] predicting on fold 4\n",
            "[07:52:19] Completed fold 4/10\n",
            "[07:52:19] Starting fold 5/10 (train n=17146, test n=1905)\n",
            "[07:52:19]   [LR] fitting on fold 5\n",
            "[07:52:19]   [LR] predicting on fold 5\n",
            "[07:52:19]   [KNN] fitting on fold 5\n",
            "[07:52:19]   [KNN] predicting on fold 5\n",
            "[07:52:20]   [DT] fitting on fold 5\n",
            "[07:52:20]   [DT] predicting on fold 5\n",
            "[07:52:20]   [RF] fitting on fold 5\n",
            "[07:52:20]   [RF] predicting on fold 5\n",
            "[07:52:20]   [SVM] fitting on fold 5\n",
            "[07:52:21]   [SVM] predicting on fold 5\n",
            "[07:52:21] Completed fold 5/10\n",
            "[07:52:21] Starting fold 6/10 (train n=17146, test n=1905)\n",
            "[07:52:21]   [LR] fitting on fold 6\n",
            "[07:52:21]   [LR] predicting on fold 6\n",
            "[07:52:21]   [KNN] fitting on fold 6\n",
            "[07:52:21]   [KNN] predicting on fold 6\n",
            "[07:52:21]   [DT] fitting on fold 6\n",
            "[07:52:21]   [DT] predicting on fold 6\n",
            "[07:52:21]   [RF] fitting on fold 6\n",
            "[07:52:21]   [RF] predicting on fold 6\n",
            "[07:52:22]   [SVM] fitting on fold 6\n",
            "[07:52:22]   [SVM] predicting on fold 6\n",
            "[07:52:22] Completed fold 6/10\n",
            "[07:52:22] Starting fold 7/10 (train n=17146, test n=1905)\n",
            "[07:52:22]   [LR] fitting on fold 7\n",
            "[07:52:22]   [LR] predicting on fold 7\n",
            "[07:52:22]   [KNN] fitting on fold 7\n",
            "[07:52:22]   [KNN] predicting on fold 7\n",
            "[07:52:22]   [DT] fitting on fold 7\n",
            "[07:52:22]   [DT] predicting on fold 7\n",
            "[07:52:22]   [RF] fitting on fold 7\n",
            "[07:52:23]   [RF] predicting on fold 7\n",
            "[07:52:23]   [SVM] fitting on fold 7\n",
            "[07:52:23]   [SVM] predicting on fold 7\n",
            "[07:52:23] Completed fold 7/10\n",
            "[07:52:23] Starting fold 8/10 (train n=17146, test n=1905)\n",
            "[07:52:23]   [LR] fitting on fold 8\n",
            "[07:52:23]   [LR] predicting on fold 8\n",
            "[07:52:23]   [KNN] fitting on fold 8\n",
            "[07:52:23]   [KNN] predicting on fold 8\n",
            "[07:52:23]   [DT] fitting on fold 8\n",
            "[07:52:23]   [DT] predicting on fold 8\n",
            "[07:52:23]   [RF] fitting on fold 8\n",
            "[07:52:24]   [RF] predicting on fold 8\n",
            "[07:52:24]   [SVM] fitting on fold 8\n",
            "[07:52:24]   [SVM] predicting on fold 8\n",
            "[07:52:24] Completed fold 8/10\n",
            "[07:52:24] Starting fold 9/10 (train n=17146, test n=1905)\n",
            "[07:52:24]   [LR] fitting on fold 9\n",
            "[07:52:24]   [LR] predicting on fold 9\n",
            "[07:52:24]   [KNN] fitting on fold 9\n",
            "[07:52:24]   [KNN] predicting on fold 9\n",
            "[07:52:24]   [DT] fitting on fold 9\n",
            "[07:52:24]   [DT] predicting on fold 9\n",
            "[07:52:24]   [RF] fitting on fold 9\n",
            "[07:52:25]   [RF] predicting on fold 9\n",
            "[07:52:25]   [SVM] fitting on fold 9\n",
            "[07:52:25]   [SVM] predicting on fold 9\n",
            "[07:52:25] Completed fold 9/10\n",
            "[07:52:25] Starting fold 10/10 (train n=17146, test n=1905)\n",
            "[07:52:25]   [LR] fitting on fold 10\n",
            "[07:52:25]   [LR] predicting on fold 10\n",
            "[07:52:25]   [KNN] fitting on fold 10\n",
            "[07:52:25]   [KNN] predicting on fold 10\n",
            "[07:52:25]   [DT] fitting on fold 10\n",
            "[07:52:25]   [DT] predicting on fold 10\n",
            "[07:52:25]   [RF] fitting on fold 10\n",
            "[07:52:26]   [RF] predicting on fold 10\n",
            "[07:52:26]   [SVM] fitting on fold 10\n",
            "[07:52:26]   [SVM] predicting on fold 10\n",
            "[07:52:26] Completed fold 10/10\n",
            "[07:52:26] Aggregating per-fold differences into Wilcoxon tests\n",
            "[07:52:26] Computing Wilcoxon p-values for model LR\n",
            "[07:52:26] Computing Wilcoxon p-values for model KNN\n",
            "[07:52:26] Computing Wilcoxon p-values for model DT\n",
            "[07:52:26] Computing Wilcoxon p-values for model RF\n",
            "[07:52:26] Computing Wilcoxon p-values for model SVM\n",
            "[07:52:26] Final table for this dataset:\n",
            "[07:52:26] \n",
            "                                      LR                KNN            DT            RF           SVM\n",
            "Demographic parity                     …                  …             …             …             …\n",
            "Equalised odds              TPR=…, FPR=…  TPR=…, FPR=0.0273  TPR=…, FPR=…  TPR=…, FPR=…  TPR=…, FPR=…\n",
            "Equal opportunity                      …                  …             …             …             …\n",
            "False positive rate parity             …             0.0273             …             …             …\n",
            "Treatment equality                     …                  …             …             …             …\n",
            "Discrimination score              0.0020                  …        0.0020        0.0020        0.0020\n",
            "Disparate Impact                       …                  …             …             …             …\n",
            "Balanced Error Rate                    …                  …             …             …             …\n",
            "[07:52:26] Saved fairness_table_D73.csv\n",
            "[07:52:26] Saved fairness_table_D73.xlsx\n",
            "[07:52:26] === Done D73 ===\n",
            "[07:52:26] Writing combined multi-sheet Excel: fairness_tables_all.xlsx\n",
            "[07:52:26] Could not write combined Excel: No module named 'xlsxwriter'\n",
            "[07:52:26] All done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jKBeQ8_qKxiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import wasserstein_distance\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==========================\n",
        "# Configuration\n",
        "# ==========================\n",
        "DATASETS = {\n",
        "    # D7: remove 81 males from class 0\n",
        "    \"D7\": {\n",
        "        \"path\": \"D7.csv\",\n",
        "        \"gender_col\": \"gender\",                 # 1=Male, 2=Female\n",
        "        \"label_col\": \"cardio\",                  # 0/1\n",
        "        \"gender_map\": {1: 1, 2: 0},             # Male=1, Female=0\n",
        "        \"removal\": {\"gender\": 1, \"label\": 0, \"n\": 162}, #81\n",
        "    },\n",
        "    # D58: remove 17,213 females from class 0\n",
        "    \"D58\": {\n",
        "        \"path\": \"D58.csv\",\n",
        "        \"gender_col\": \"Sex\",                    # 0=Female, 1=Male\n",
        "        \"label_col\": \"Diabetes_binary\",         # 0/1\n",
        "        \"gender_map\": {0: 0, 1: 1},             # Male=1, Female=0\n",
        "        \"removal\": {\"gender\": 0, \"label\": 0, \"n\": 34426}, #17213\n",
        "    },\n",
        "    # D73: remove 460 males from class 0 (0=dead)\n",
        "    \"D73\": {\n",
        "        \"path\": \"D73.csv\",\n",
        "        \"gender_col\": \"sex_0male_1female\",      # 0=Male, 1=Female\n",
        "        \"label_col\": \"hospital_outcome_1alive_0dead\",  # 1=alive, 0=dead\n",
        "        \"gender_map\": {0: 1, 1: 0},             # Male=1, Female=0\n",
        "        \"removal\": {\"gender\": 1, \"label\": 0, \"n\": 920},#460\n",
        "    },\n",
        "}\n",
        "\n",
        "REMOVAL_DESCRIPTIONS = {\n",
        "    \"D7\":  \"81, Male from 0 class\",\n",
        "    \"D58\": \"17,213, female from 0 class\",\n",
        "    \"D73\": \"460, male from 0 class\",\n",
        "}\n",
        "\n",
        "# ==========================\n",
        "# Helpers\n",
        "# ==========================\n",
        "def fmt_p(p, threshold=0.05):\n",
        "    try:\n",
        "        if p is None or np.isnan(p) or p > threshold:\n",
        "            return \"…\"\n",
        "        return f\"{p:.4f}\"\n",
        "    except Exception:\n",
        "        return \"…\"\n",
        "\n",
        "def compute_emd_pvalue_binary(all_labels01: np.ndarray,\n",
        "                              subgroup_labels01: np.ndarray,\n",
        "                              n_iter: int = 2000,\n",
        "                              seed: int = 42):\n",
        "    \"\"\"\n",
        "    EMD between subgroup label distribution and overall label distribution (binary labels).\n",
        "    Permutation bootstrap p-value using sampling without replacement.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    all_labels01 = np.asarray(all_labels01, dtype=int)\n",
        "    subgroup_labels01 = np.asarray(subgroup_labels01, dtype=int)\n",
        "\n",
        "    observed = wasserstein_distance(subgroup_labels01, all_labels01)\n",
        "\n",
        "    n = len(all_labels01)\n",
        "    k = len(subgroup_labels01)\n",
        "    boot = np.empty(n_iter, dtype=float)\n",
        "    for i in range(n_iter):\n",
        "        idx = rng.choice(n, size=k, replace=False)\n",
        "        boot[i] = wasserstein_distance(all_labels01[idx], all_labels01)\n",
        "\n",
        "    p_val = float((boot >= observed).mean())\n",
        "    return float(observed), p_val\n",
        "\n",
        "def load_and_prepare(cfg):\n",
        "    df = pd.read_csv(cfg[\"path\"])\n",
        "    # Map gender -> {Male:1, Female:0}\n",
        "    if \"gender_map\" in cfg and cfg[\"gender_map\"] is not None:\n",
        "        df[cfg[\"gender_col\"]] = df[cfg[\"gender_col\"]].map(cfg[\"gender_map\"])\n",
        "    # Coerce label to 0/1\n",
        "    df[cfg[\"label_col\"]] = (df[cfg[\"label_col\"]].astype(float) > 0).astype(int)\n",
        "    # Keep only valid rows\n",
        "    df = df.dropna(subset=[cfg[\"gender_col\"], cfg[\"label_col\"]]).copy()\n",
        "    df = df[df[cfg[\"gender_col\"]].isin([0, 1])]\n",
        "    df = df[df[cfg[\"label_col\"]].isin([0, 1])]\n",
        "    df = df.dropna(axis=0, how=\"any\")\n",
        "    return df\n",
        "\n",
        "def remove_instances(df, gender_col, label_col, gender_val, label_val, n_remove, seed=42):\n",
        "    \"\"\"\n",
        "    Remove n_remove rows uniformly at random where (gender==gender_val & label==label_val).\n",
        "    If fewer rows exist, remove all available.\n",
        "    \"\"\"\n",
        "    mask = (df[gender_col] == gender_val) & (df[label_col] == label_val)\n",
        "    idx = df[mask].index\n",
        "    if len(idx) == 0:\n",
        "        return df\n",
        "    n = min(n_remove, len(idx))\n",
        "    rng = np.random.default_rng(seed)\n",
        "    drop_idx = rng.choice(idx, size=n, replace=False)\n",
        "    return df.drop(index=drop_idx)\n",
        "\n",
        "def emd_table_for_dataset(tag, cfg, n_iter=2000, seed=42):\n",
        "    df = load_and_prepare(cfg)\n",
        "\n",
        "    # Apply specified removal\n",
        "    rem = cfg.get(\"removal\", None)\n",
        "    if rem is not None:\n",
        "        df = remove_instances(\n",
        "            df,\n",
        "            gender_col=cfg[\"gender_col\"],\n",
        "            label_col=cfg[\"label_col\"],\n",
        "            gender_val=rem[\"gender\"],\n",
        "            label_val=rem[\"label\"],\n",
        "            n_remove=rem[\"n\"],\n",
        "            seed=seed,\n",
        "        )\n",
        "\n",
        "    # Build arrays\n",
        "    y = df[cfg[\"label_col\"]].astype(int).values\n",
        "    g = df[cfg[\"gender_col\"]].astype(int).values  # Male=1, Female=0\n",
        "\n",
        "    female_mask = (g == 0)\n",
        "    male_mask   = (g == 1)\n",
        "\n",
        "    all_labels    = y\n",
        "    female_labels = y[female_mask]\n",
        "    male_labels   = y[male_mask]\n",
        "\n",
        "    fem_emd, fem_p = compute_emd_pvalue_binary(all_labels, female_labels, n_iter=n_iter, seed=seed)\n",
        "    mal_emd, mal_p = compute_emd_pvalue_binary(all_labels, male_labels,   n_iter=n_iter, seed=seed)\n",
        "\n",
        "    out = pd.DataFrame([\n",
        "        {\"Dataset\": tag, \"Removal of data instances\": REMOVAL_DESCRIPTIONS.get(tag, \"\"), \"Group\": \"Female\",\n",
        "         \"EMD value\": round(fem_emd, 6), \"p-value\": fmt_p(fem_p),\n",
        "         \"Exhibit data bias?\": \"Yes\" if (isinstance(fem_p, float) and fem_p <= 0.05) else \"No\"},\n",
        "        {\"Dataset\": tag, \"Removal of data instances\": \"\", \"Group\": \"Male\",\n",
        "         \"EMD value\": round(mal_emd, 6), \"p-value\": fmt_p(mal_p),\n",
        "         \"Exhibit data bias?\": \"Yes\" if (isinstance(mal_p, float) and mal_p <= 0.05) else \"No\"},\n",
        "    ])\n",
        "    return out\n",
        "\n",
        "# ==========================\n",
        "# Main\n",
        "# ==========================\n",
        "def main():\n",
        "    tables = []\n",
        "    for tag, cfg in DATASETS.items():\n",
        "        t = emd_table_for_dataset(tag, cfg, n_iter=2000, seed=42)\n",
        "        tables.append(t)\n",
        "    table = pd.concat(tables, ignore_index=True)\n",
        "\n",
        "    # Pretty print\n",
        "    pd.set_option(\"display.max_colwidth\", None)\n",
        "    print(\"\\n=== EMD Bias Table after Specified Instance Removal ===\")\n",
        "    print(table.to_string(index=False))\n",
        "\n",
        "    # Save\n",
        "    table.to_csv(\"emd_bias_table_after_specified_removal.csv\", index=False)\n",
        "    try:\n",
        "        table.to_excel(\"emd_bias_table_after_specified_removal.xlsx\", index=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2miWD-JMcK3",
        "outputId": "1374e3e2-d6ed-4562-8665-96f4f1b28a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== EMD Bias Table after Specified Instance Removal ===\n",
            "Dataset   Removal of data instances  Group  EMD value p-value Exhibit data bias?\n",
            "     D7       81, Male from 0 class Female   0.004372       …                 No\n",
            "     D7                               Male   0.002358       …                 No\n",
            "    D58 17,213, female from 0 class Female   0.014705  0.0000                Yes\n",
            "    D58                               Male   0.011588  0.0000                Yes\n",
            "    D73      460, male from 0 class Female   0.034514  0.0000                Yes\n",
            "    D73                               Male   0.030773  0.0000                Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==========================\n",
        "# Dataset configs\n",
        "# ==========================\n",
        "DATASETS = {\n",
        "    \"D7\": {\n",
        "        \"path\": \"D7.csv\",\n",
        "        \"gender_col\": \"gender\",\n",
        "        \"label_col\": \"cardio\",\n",
        "        \"gender_map\": {1: 1, 2: 0},  # Male=1, Female=0\n",
        "        \"removal\": {\"gender\": 1, \"label\": 0, \"n\": 81}\n",
        "    },\n",
        "    \"D58\": {\n",
        "        \"path\": \"D58.csv\",\n",
        "        \"gender_col\": \"Sex\",\n",
        "        \"label_col\": \"Diabetes_binary\",\n",
        "        \"gender_map\": {0: 0, 1: 1},  # Female=0, Male=1\n",
        "        \"removal\": {\"gender\": 0, \"label\": 0, \"n\": 17213}\n",
        "    },\n",
        "    \"D73\": {\n",
        "        \"path\": \"D73.csv\",\n",
        "        \"gender_col\": \"sex_0male_1female\",\n",
        "        \"label_col\": \"hospital_outcome_1alive_0dead\",\n",
        "        \"gender_map\": {0: 1, 1: 0},  # Male=1, Female=0\n",
        "        \"removal\": {\"gender\": 1, \"label\": 0, \"n\": 460}\n",
        "    }\n",
        "}\n",
        "\n",
        "# ==========================\n",
        "# Models\n",
        "# ==========================\n",
        "MODELS = {\n",
        "    \"LR\": LogisticRegression(max_iter=2000),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"DT\": DecisionTreeClassifier(random_state=42),\n",
        "    \"RF\": RandomForestClassifier(random_state=42),\n",
        "    \"SVM\": SVC(probability=False)  # may be slower\n",
        "}\n",
        "\n",
        "# ==========================\n",
        "# Helpers\n",
        "# ==========================\n",
        "def load_and_prepare(cfg):\n",
        "    df = pd.read_csv(cfg[\"path\"])\n",
        "    df[cfg[\"gender_col\"]] = df[cfg[\"gender_col\"]].map(cfg[\"gender_map\"])\n",
        "    df[cfg[\"label_col\"]] = (df[cfg[\"label_col\"]].astype(float) > 0).astype(int)\n",
        "    df = df.dropna(subset=[cfg[\"gender_col\"], cfg[\"label_col\"]])\n",
        "    return df\n",
        "\n",
        "def remove_instances(df, cfg, seed=42):\n",
        "    rem = cfg.get(\"removal\", None)\n",
        "    if rem is None:\n",
        "        return df\n",
        "    mask = (df[cfg[\"gender_col\"]] == rem[\"gender\"]) & (df[cfg[\"label_col\"]] == rem[\"label\"])\n",
        "    idx = df[mask].index\n",
        "    if len(idx) == 0:\n",
        "        return df\n",
        "    n = min(rem[\"n\"], len(idx))\n",
        "    rng = np.random.default_rng(seed)\n",
        "    drop_idx = rng.choice(idx, size=n, replace=False)\n",
        "    return df.drop(index=drop_idx)\n",
        "\n",
        "def evaluate_models(X_train, X_test, y_train, y_test):\n",
        "    results = {}\n",
        "    for name, model in MODELS.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_train)  # training phase results\n",
        "        results[name] = {\n",
        "            \"Accuracy\": accuracy_score(y_train, y_pred),\n",
        "            \"Precision\": precision_score(y_train, y_pred, zero_division=0),\n",
        "            \"Recall\": recall_score(y_train, y_pred, zero_division=0),\n",
        "            \"F1-score\": f1_score(y_train, y_pred, zero_division=0)\n",
        "        }\n",
        "    return results\n",
        "\n",
        "# ==========================\n",
        "# Main\n",
        "# ==========================\n",
        "def main():\n",
        "    all_tables = {}\n",
        "    for tag, cfg in DATASETS.items():\n",
        "        df_orig = load_and_prepare(cfg)\n",
        "\n",
        "        # features: drop gender & label (keep all else as predictors)\n",
        "        X = df_orig.drop(columns=[cfg[\"label_col\"], cfg[\"gender_col\"]])\n",
        "        y = df_orig[cfg[\"label_col\"]]\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        results_before = evaluate_models(X_train, X_test, y_train, y_test)\n",
        "\n",
        "        # After removal\n",
        "        df_after = remove_instances(df_orig.copy(), cfg)\n",
        "        X2 = df_after.drop(columns=[cfg[\"label_col\"], cfg[\"gender_col\"]])\n",
        "        y2 = df_after[cfg[\"label_col\"]]\n",
        "\n",
        "        X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "            X2, y2, test_size=0.2, random_state=42, stratify=y2\n",
        "        )\n",
        "\n",
        "        results_after = evaluate_models(X2_train, X2_test, y2_train, y2_test)\n",
        "\n",
        "        # Build comparison table\n",
        "        rows = []\n",
        "        for model in MODELS.keys():\n",
        "            rows.append({\n",
        "                \"Model\": model,\n",
        "                \"Acc_Before\": round(results_before[model][\"Accuracy\"], 4),\n",
        "                \"Prec_Before\": round(results_before[model][\"Precision\"], 4),\n",
        "                \"Rec_Before\": round(results_before[model][\"Recall\"], 4),\n",
        "                \"F1_Before\": round(results_before[model][\"F1-score\"], 4),\n",
        "                \"Acc_After\": round(results_after[model][\"Accuracy\"], 4),\n",
        "                \"Prec_After\": round(results_after[model][\"Precision\"], 4),\n",
        "                \"Rec_After\": round(results_after[model][\"Recall\"], 4),\n",
        "                \"F1_After\": round(results_after[model][\"F1-score\"], 4),\n",
        "            })\n",
        "        all_tables[tag] = pd.DataFrame(rows)\n",
        "\n",
        "        print(f\"\\n=== {tag} Results ===\")\n",
        "        print(all_tables[tag].to_string(index=False))\n",
        "\n",
        "        all_tables[tag].to_csv(f\"{tag}_before_after_metrics.csv\", index=False)\n",
        "\n",
        "    return all_tables\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    tables = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAOC1X4QMdqe",
        "outputId": "1352377b-1159-4c27-b55c-49356d838d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== D7 Results ===\n",
            "Model  Acc_Before  Prec_Before  Rec_Before  F1_Before  Acc_After  Prec_After  Rec_After  F1_After\n",
            "   LR      0.7038       0.7208      0.6647     0.6916     0.7074      0.7260     0.6668    0.6951\n",
            "  KNN      0.7145       0.7160      0.7103     0.7132     0.7155      0.7174     0.7116    0.7145\n",
            "   DT      1.0000       1.0000      1.0000     1.0000     1.0000      1.0000     1.0000    1.0000\n",
            "   RF      1.0000       1.0000      1.0000     1.0000     1.0000      1.0000     1.0000    1.0000\n",
            "  SVM      0.5987       0.5874      0.6619     0.6224     0.5981      0.5863     0.6680    0.6245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC  # fast linear SVM (kept as SVM per requirement)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==========================\n",
        "# Progress / logging\n",
        "# ==========================\n",
        "VERBOSE = True\n",
        "def log(msg):\n",
        "    if VERBOSE:\n",
        "        ts = time.strftime(\"%H:%M:%S\")\n",
        "        print(f\"[{ts}] {msg}\", file=sys.stdout, flush=True)\n",
        "\n",
        "# ==========================\n",
        "# Dataset configs (80:20 split; results on TRAINING predictions)\n",
        "# ==========================\n",
        "DATASETS = {\n",
        "    \"D58\": {\n",
        "        \"path\": \"D58.csv\",\n",
        "        \"gender_col\": \"Sex\",                           # 0=Female, 1=Male\n",
        "        \"label_col\": \"Diabetes_binary\",                # 0/1\n",
        "        \"gender_map\": {0: 0, 1: 1},                    # Female=0, Male=1\n",
        "        \"removal\": {\"gender\": 0, \"label\": 0, \"n\": 17213}, # remove 17,213 females from class 0\n",
        "    },\n",
        "    \"D73\": {\n",
        "        \"path\": \"D73.csv\",\n",
        "        \"gender_col\": \"sex_0male_1female\",             # 0=Male, 1=Female\n",
        "        \"label_col\": \"hospital_outcome_1alive_0dead\",  # 1=alive, 0=dead\n",
        "        \"gender_map\": {0: 1, 1: 0},                    # Male=1, Female=0\n",
        "        \"removal\": {\"gender\": 1, \"label\": 0, \"n\": 460},   # remove 460 males from class 0 (dead)\n",
        "    },\n",
        "}\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "# ==========================\n",
        "# Models (keep SVM; use LinearSVC for speed)\n",
        "# ==========================\n",
        "def get_models():\n",
        "    models = {\n",
        "        \"LR\": Pipeline([\n",
        "            (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "            (\"clf\", LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))\n",
        "        ]),\n",
        "        \"KNN\": Pipeline([\n",
        "            (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "            (\"clf\", KNeighborsClassifier(n_neighbors=5))\n",
        "        ]),\n",
        "        \"DT\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "        \"RF\": RandomForestClassifier(\n",
        "            n_estimators=200,        # tuned down for speed\n",
        "            max_depth=None,\n",
        "            n_jobs=-1,\n",
        "            random_state=RANDOM_STATE\n",
        "        ),\n",
        "        # Keep SVM: LinearSVC (fast). Still an SVM (hinge loss, linear kernel).\n",
        "        \"SVM\": Pipeline([\n",
        "            (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "            (\"clf\", LinearSVC(C=1.0, max_iter=5000, random_state=RANDOM_STATE))\n",
        "        ]),\n",
        "    }\n",
        "    return models\n",
        "\n",
        "# ==========================\n",
        "# Helpers\n",
        "# ==========================\n",
        "def load_and_prepare(cfg):\n",
        "    log(f\"Loading: {cfg['path']}\")\n",
        "    df = pd.read_csv(cfg[\"path\"])\n",
        "    log(f\"Loaded shape: {df.shape}\")\n",
        "\n",
        "    # Map gender -> {Male:1, Female:0}\n",
        "    if \"gender_map\" in cfg and cfg[\"gender_map\"] is not None:\n",
        "        before_unique = df[cfg[\"gender_col\"]].unique()\n",
        "        df[cfg[\"gender_col\"]] = df[cfg[\"gender_col\"]].map(cfg[\"gender_map\"])\n",
        "        after_unique = df[cfg[\"gender_col\"]].unique()\n",
        "        log(f\"Mapped gender '{cfg['gender_col']}' values {before_unique} -> {after_unique}\")\n",
        "\n",
        "    # Coerce label to 0/1 (strict)\n",
        "    before_label_unique = df[cfg[\"label_col\"]].unique()\n",
        "    df[cfg[\"label_col\"]] = (df[cfg[\"label_col\"]].astype(float) > 0).astype(int)\n",
        "    after_label_unique = df[cfg[\"label_col\"]].unique()\n",
        "    log(f\"Coerced label '{cfg['label_col']}' {before_label_unique} -> {after_label_unique}\")\n",
        "\n",
        "    # Keep valid rows\n",
        "    used_cols = [cfg[\"gender_col\"], cfg[\"label_col\"]]\n",
        "    before = len(df)\n",
        "    df = df.dropna(subset=used_cols).copy()\n",
        "    df = df[df[cfg[\"gender_col\"]].isin([0, 1])]\n",
        "    df = df[df[cfg[\"label_col\"]].isin([0, 1])]\n",
        "    after = len(df)\n",
        "    log(f\"Filtered invalid rows: {before - after} removed, remaining: {after}\")\n",
        "\n",
        "    # Drop remaining NA in features\n",
        "    before = len(df)\n",
        "    df = df.dropna(axis=0, how=\"any\")\n",
        "    after = len(df)\n",
        "    if after < before:\n",
        "        log(f\"Dropped rows with NA in features: {before - after}, remaining: {after}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def remove_instances(df, cfg, seed=RANDOM_STATE):\n",
        "    rem = cfg.get(\"removal\", None)\n",
        "    if rem is None:\n",
        "        return df, 0\n",
        "    g_col, y_col = cfg[\"gender_col\"], cfg[\"label_col\"]\n",
        "    mask = (df[g_col] == rem[\"gender\"]) & (df[y_col] == rem[\"label\"])\n",
        "    idx = df[mask].index\n",
        "    n_avail = len(idx)\n",
        "    n = min(rem[\"n\"], n_avail)\n",
        "    if n == 0:\n",
        "        log(\"No matching instances to remove.\")\n",
        "        return df, 0\n",
        "    rng = np.random.default_rng(seed)\n",
        "    drop_idx = rng.choice(idx, size=n, replace=False)\n",
        "    df2 = df.drop(index=drop_idx)\n",
        "    log(f\"Removed {n} rows (requested {rem['n']}, available {n_avail}) \"\n",
        "        f\"where gender={rem['gender']}, label={rem['label']}. New shape: {df2.shape}\")\n",
        "    return df2, n\n",
        "\n",
        "def split_xy(df, cfg):\n",
        "    # Features: all numeric columns except gender & label\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    feat_cols = [c for c in numeric_cols if c not in {cfg[\"gender_col\"], cfg[\"label_col\"]}]\n",
        "    X = df[feat_cols].values\n",
        "    y = df[cfg[\"label_col\"]].values\n",
        "    return X, y, feat_cols\n",
        "\n",
        "def evaluate_on_training(X_train, y_train):\n",
        "    models = get_models()\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        t0 = time.time()\n",
        "        log(f\"  [{name}] fit on training set: n={X_train.shape[0]}, d={X_train.shape[1]}\")\n",
        "        model.fit(X_train, y_train)\n",
        "        t1 = time.time()\n",
        "        y_pred = model.predict(X_train)\n",
        "        acc = accuracy_score(y_train, y_pred)\n",
        "        prec = precision_score(y_train, y_pred, zero_division=0)\n",
        "        rec = recall_score(y_train, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_train, y_pred, zero_division=0)\n",
        "        dt = t1 - t0\n",
        "        log(f\"  [{name}] done. Train Acc={acc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f} (fit {dt:.2f}s)\")\n",
        "        results[name] = {\"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1-score\": f1, \"fit_seconds\": dt}\n",
        "    return results\n",
        "\n",
        "def format_table(results_before, results_after):\n",
        "    rows = []\n",
        "    for name in [\"LR\", \"KNN\", \"DT\", \"RF\", \"SVM\"]:\n",
        "        b = results_before[name]\n",
        "        a = results_after[name]\n",
        "        rows.append({\n",
        "            \"Model\": name,\n",
        "            \"Accuracy (Before)\": round(b[\"Accuracy\"], 4),\n",
        "            \"Precision (Before)\": round(b[\"Precision\"], 4),\n",
        "            \"Recall (Before)\": round(b[\"Recall\"], 4),\n",
        "            \"F1-score (Before)\": round(b[\"F1-score\"], 4),\n",
        "            \"Accuracy (After)\": round(a[\"Accuracy\"], 4),\n",
        "            \"Precision (After)\": round(a[\"Precision\"], 4),\n",
        "            \"Recall (After)\": round(a[\"Recall\"], 4),\n",
        "            \"F1-score (After)\": round(a[\"F1-score\"], 4),\n",
        "        })\n",
        "    cols = [\n",
        "        \"Model\",\n",
        "        \"Accuracy (Before)\", \"Precision (Before)\", \"Recall (Before)\", \"F1-score (Before)\",\n",
        "        \"Accuracy (After)\",  \"Precision (After)\",  \"Recall (After)\",  \"F1-score (After)\"\n",
        "    ]\n",
        "    return pd.DataFrame(rows, columns=cols)\n",
        "\n",
        "# ==========================\n",
        "# Orchestrator\n",
        "# ==========================\n",
        "def run_dataset(tag, cfg):\n",
        "    log(f\"\\n=== [{tag}] START ===\")\n",
        "    df = load_and_prepare(cfg)\n",
        "\n",
        "    # 80:20 split (original dataset)\n",
        "    X, y, feat_cols = split_xy(df, cfg)\n",
        "    log(f\"[{tag}] Features: {len(feat_cols)}; Splitting 80:20 (original)\")\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
        "    )\n",
        "    log(f\"[{tag}] Train n={X_tr.shape[0]}, Test n={X_te.shape[0]} (original)\")\n",
        "    log(f\"[{tag}] Training models on ORIGINAL training set (printing training metrics)\")\n",
        "    res_before = evaluate_on_training(X_tr, y_tr)\n",
        "\n",
        "    # Apply removal, then split again and train\n",
        "    log(f\"[{tag}] Applying instance removal\")\n",
        "    df_after, n_removed = remove_instances(df, cfg)\n",
        "    X2, y2, feat_cols2 = split_xy(df_after, cfg)\n",
        "    log(f\"[{tag}] Features after removal: {len(feat_cols2)}; Splitting 80:20 (after removal)\")\n",
        "    X2_tr, X2_te, y2_tr, y2_te = train_test_split(\n",
        "        X2, y2, test_size=TEST_SIZE, stratify=y2, random_state=RANDOM_STATE\n",
        "    )\n",
        "    log(f\"[{tag}] Train n={X2_tr.shape[0]}, Test n={X2_te.shape[0]} (after removal)\")\n",
        "    log(f\"[{tag}] Training models on AFTER-REMOVAL training set (printing training metrics)\")\n",
        "    res_after = evaluate_on_training(X2_tr, y2_tr)\n",
        "\n",
        "    table = format_table(res_before, res_after)\n",
        "    log(f\"[{tag}] Table complete:\")\n",
        "    log(\"\\n\" + table.to_string(index=False))\n",
        "\n",
        "    # Save per-dataset CSV/Excel\n",
        "    out_csv = f\"{tag}_before_after_training_metrics.csv\"\n",
        "    table.to_csv(out_csv, index=False)\n",
        "    try:\n",
        "        table.to_excel(f\"{tag}_before_after_training_metrics.xlsx\", index=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    log(f\"=== [{tag}] DONE ===\")\n",
        "    return table\n",
        "\n",
        "def main():\n",
        "    log(\"Starting before/after training metrics (80:20 split, training predictions)\")\n",
        "    all_tables = {}\n",
        "    for tag, cfg in DATASETS.items():\n",
        "        all_tables[tag] = run_dataset(tag, cfg)\n",
        "\n",
        "    # Optional: combined workbook\n",
        "    try:\n",
        "        log(\"Writing combined workbook: before_after_training_metrics_all.xlsx\")\n",
        "        with pd.ExcelWriter(\"before_after_training_metrics_all.xlsx\", engine=\"xlsxwriter\") as writer:\n",
        "            for tag, tbl in all_tables.items():\n",
        "                tbl.to_excel(writer, sheet_name=tag, index=False)\n",
        "        log(\"Saved before_after_training_metrics_all.xlsx\")\n",
        "    except Exception as e:\n",
        "        log(f\"Could not write combined Excel: {e}\")\n",
        "\n",
        "    log(\"All datasets complete.\")\n",
        "    return all_tables\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReytgxajOkYH",
        "outputId": "7ab5547c-4eda-44f1-be51-e17cb195ba8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09:29:42] Starting before/after training metrics (80:20 split, training predictions)\n",
            "[09:29:42] \n",
            "=== [D58] START ===\n",
            "[09:29:42] Loading: D58.csv\n",
            "[09:29:43] Loaded shape: (236378, 22)\n",
            "[09:29:43] Mapped gender 'Sex' values [0 1] -> [0 1]\n",
            "[09:29:43] Coerced label 'Diabetes_binary' [0. 1.] -> [0 1]\n",
            "[09:29:43] Filtered invalid rows: 0 removed, remaining: 236378\n",
            "[09:29:43] [D58] Features: 20; Splitting 80:20 (original)\n",
            "[09:29:44] [D58] Train n=189102, Test n=47276 (original)\n",
            "[09:29:44] [D58] Training models on ORIGINAL training set (printing training metrics)\n",
            "[09:29:44]   [LR] fit on training set: n=189102, d=20\n",
            "[09:29:44]   [LR] done. Train Acc=0.8607, Prec=0.5346, Rec=0.1458, F1=0.2290 (fit 0.56s)\n",
            "[09:29:44]   [KNN] fit on training set: n=189102, d=20\n",
            "[09:33:11]   [KNN] done. Train Acc=0.8830, Prec=0.6702, Rec=0.3470, F1=0.4573 (fit 0.10s)\n",
            "[09:33:11]   [DT] fit on training set: n=189102, d=20\n",
            "[09:33:13]   [DT] done. Train Acc=0.9932, Prec=0.9986, Rec=0.9532, F1=0.9753 (fit 1.87s)\n",
            "[09:33:13]   [RF] fit on training set: n=189102, d=20\n",
            "[09:34:08]   [RF] done. Train Acc=0.9932, Prec=0.9947, Rec=0.9570, F1=0.9754 (fit 45.29s)\n",
            "[09:34:08]   [SVM] fit on training set: n=189102, d=20\n",
            "[09:34:09]   [SVM] done. Train Acc=0.8611, Prec=0.6007, Rec=0.0646, F1=0.1167 (fit 0.90s)\n",
            "[09:34:09] [D58] Applying instance removal\n",
            "[09:34:09] Removed 17213 rows (requested 17213, available 107328) where gender=0, label=0. New shape: (219165, 22)\n",
            "[09:34:09] [D58] Features after removal: 20; Splitting 80:20 (after removal)\n",
            "[09:34:09] [D58] Train n=175332, Test n=43833 (after removal)\n",
            "[09:34:09] [D58] Training models on AFTER-REMOVAL training set (printing training metrics)\n",
            "[09:34:09]   [LR] fit on training set: n=175332, d=20\n",
            "[09:34:10]   [LR] done. Train Acc=0.8514, Prec=0.5475, Rec=0.1706, F1=0.2602 (fit 0.47s)\n",
            "[09:34:10]   [KNN] fit on training set: n=175332, d=20\n",
            "[09:37:09]   [KNN] done. Train Acc=0.8758, Prec=0.6703, Rec=0.3724, F1=0.4788 (fit 0.09s)\n",
            "[09:37:09]   [DT] fit on training set: n=175332, d=20\n",
            "[09:37:10]   [DT] done. Train Acc=0.9930, Prec=0.9986, Rec=0.9555, F1=0.9766 (fit 0.87s)\n",
            "[09:37:10]   [RF] fit on training set: n=175332, d=20\n",
            "[09:37:55]   [RF] done. Train Acc=0.9930, Prec=0.9945, Rec=0.9594, F1=0.9766 (fit 37.38s)\n",
            "[09:37:55]   [SVM] fit on training set: n=175332, d=20\n",
            "[09:37:56]   [SVM] done. Train Acc=0.8518, Prec=0.6058, Rec=0.0926, F1=0.1607 (fit 0.88s)\n",
            "[09:37:56] [D58] Table complete:\n",
            "[09:37:56] \n",
            "Model  Accuracy (Before)  Precision (Before)  Recall (Before)  F1-score (Before)  Accuracy (After)  Precision (After)  Recall (After)  F1-score (After)\n",
            "   LR             0.8607              0.5346           0.1458             0.2290            0.8514             0.5475          0.1706            0.2602\n",
            "  KNN             0.8830              0.6702           0.3470             0.4573            0.8758             0.6703          0.3724            0.4788\n",
            "   DT             0.9932              0.9986           0.9532             0.9753            0.9930             0.9986          0.9555            0.9766\n",
            "   RF             0.9932              0.9947           0.9570             0.9754            0.9930             0.9945          0.9594            0.9766\n",
            "  SVM             0.8611              0.6007           0.0646             0.1167            0.8518             0.6058          0.0926            0.1607\n",
            "[09:37:56] === [D58] DONE ===\n",
            "[09:37:56] \n",
            "=== [D73] START ===\n",
            "[09:37:56] Loading: D73.csv\n",
            "[09:37:56] Loaded shape: (19051, 4)\n",
            "[09:37:56] Mapped gender 'sex_0male_1female' values [1 0] -> [0 1]\n",
            "[09:37:56] Coerced label 'hospital_outcome_1alive_0dead' [1 0] -> [1 0]\n",
            "[09:37:56] Filtered invalid rows: 0 removed, remaining: 19051\n",
            "[09:37:56] [D73] Features: 2; Splitting 80:20 (original)\n",
            "[09:37:56] [D73] Train n=15240, Test n=3811 (original)\n",
            "[09:37:56] [D73] Training models on ORIGINAL training set (printing training metrics)\n",
            "[09:37:56]   [LR] fit on training set: n=15240, d=2\n",
            "[09:37:56]   [LR] done. Train Acc=0.8107, Prec=0.8107, Rec=1.0000, F1=0.8955 (fit 0.01s)\n",
            "[09:37:56]   [KNN] fit on training set: n=15240, d=2\n",
            "[09:37:57]   [KNN] done. Train Acc=0.7696, Prec=0.8143, Rec=0.9272, F1=0.8671 (fit 0.03s)\n",
            "[09:37:57]   [DT] fit on training set: n=15240, d=2\n",
            "[09:37:57]   [DT] done. Train Acc=0.8113, Prec=0.8117, Rec=0.9989, F1=0.8956 (fit 0.01s)\n",
            "[09:37:57]   [RF] fit on training set: n=15240, d=2\n",
            "[09:37:59]   [RF] done. Train Acc=0.8113, Prec=0.8112, Rec=0.9999, F1=0.8957 (fit 1.69s)\n",
            "[09:37:59]   [SVM] fit on training set: n=15240, d=2\n",
            "[09:37:59]   [SVM] done. Train Acc=0.8107, Prec=0.8107, Rec=1.0000, F1=0.8955 (fit 0.01s)\n",
            "[09:37:59] [D73] Applying instance removal\n",
            "[09:37:59] Removed 460 rows (requested 460, available 2045) where gender=1, label=0. New shape: (18591, 4)\n",
            "[09:37:59] [D73] Features after removal: 2; Splitting 80:20 (after removal)\n",
            "[09:37:59] [D73] Train n=14872, Test n=3719 (after removal)\n",
            "[09:37:59] [D73] Training models on AFTER-REMOVAL training set (printing training metrics)\n",
            "[09:37:59]   [LR] fit on training set: n=14872, d=2\n",
            "[09:37:59]   [LR] done. Train Acc=0.8308, Prec=0.8308, Rec=1.0000, F1=0.9076 (fit 0.01s)\n",
            "[09:37:59]   [KNN] fit on training set: n=14872, d=2\n",
            "[09:37:59]   [KNN] done. Train Acc=0.8123, Prec=0.8317, Rec=0.9705, F1=0.8957 (fit 0.01s)\n",
            "[09:37:59]   [DT] fit on training set: n=14872, d=2\n",
            "[09:37:59]   [DT] done. Train Acc=0.8314, Prec=0.8317, Rec=0.9992, F1=0.9078 (fit 0.01s)\n",
            "[09:37:59]   [RF] fit on training set: n=14872, d=2\n",
            "[09:38:00]   [RF] done. Train Acc=0.8314, Prec=0.8315, Rec=0.9996, F1=0.9078 (fit 0.99s)\n",
            "[09:38:00]   [SVM] fit on training set: n=14872, d=2\n",
            "[09:38:00]   [SVM] done. Train Acc=0.8308, Prec=0.8308, Rec=1.0000, F1=0.9076 (fit 0.01s)\n",
            "[09:38:00] [D73] Table complete:\n",
            "[09:38:00] \n",
            "Model  Accuracy (Before)  Precision (Before)  Recall (Before)  F1-score (Before)  Accuracy (After)  Precision (After)  Recall (After)  F1-score (After)\n",
            "   LR             0.8107              0.8107           1.0000             0.8955            0.8308             0.8308          1.0000            0.9076\n",
            "  KNN             0.7696              0.8143           0.9272             0.8671            0.8123             0.8317          0.9705            0.8957\n",
            "   DT             0.8113              0.8117           0.9989             0.8956            0.8314             0.8317          0.9992            0.9078\n",
            "   RF             0.8113              0.8112           0.9999             0.8957            0.8314             0.8315          0.9996            0.9078\n",
            "  SVM             0.8107              0.8107           1.0000             0.8955            0.8308             0.8308          1.0000            0.9076\n",
            "[09:38:00] === [D73] DONE ===\n",
            "[09:38:00] Writing combined workbook: before_after_training_metrics_all.xlsx\n",
            "[09:38:00] Saved before_after_training_metrics_all.xlsx\n",
            "[09:38:00] All datasets complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# D7 — Fairness-aware evaluation using Fairlearn (Demographic Parity) with verbose progress & timings\n",
        "# FIX: ThresholdOptimizer.predict requires sensitive_features at predict-time.\n",
        "# Models: LR, KNN, DT, RF, SVM(LinearSVC). Baseline is NOT trained here.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "import warnings\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
        "from fairlearn.postprocessing import ThresholdOptimizer\n",
        "\n",
        "# ===========================\n",
        "# Config\n",
        "# ===========================\n",
        "RANDOM_STATE = 42\n",
        "N_SPLITS = 10\n",
        "P_THRESHOLD = 0.05\n",
        "VERBOSE = True\n",
        "\n",
        "D7_CFG = {\n",
        "    \"path\": \"D7.csv\",\n",
        "    \"gender_col\": \"gender\",       # 1=Male, 2=Female\n",
        "    \"label_col\": \"cardio\",        # 0/1\n",
        "    \"gender_map\": {1: 1, 2: 0},   # Male=1, Female=0\n",
        "}\n",
        "\n",
        "def log(msg):\n",
        "    if VERBOSE:\n",
        "        ts = time.strftime(\"%H:%M:%S\")\n",
        "        print(f\"[{ts}] {msg}\", file=sys.stdout, flush=True)\n",
        "\n",
        "# ===========================\n",
        "# Helpers\n",
        "# ===========================\n",
        "def fmt_p(p):\n",
        "    try:\n",
        "        if p is None or np.isnan(p) or p > P_THRESHOLD:\n",
        "            return \"…\"\n",
        "        return f\"{p:.4f}\"\n",
        "    except Exception:\n",
        "        return \"…\"\n",
        "\n",
        "def safe_div(a, b):\n",
        "    return np.nan if (b is None or b == 0) else (a / b)\n",
        "\n",
        "def confusion_by_group(y_true, y_pred, group_mask):\n",
        "    yt = y_true[group_mask]\n",
        "    yp = y_pred[group_mask]\n",
        "    if yt.size == 0:\n",
        "        return dict(TP=0, FP=0, TN=0, FN=0, TPR=np.nan, FPR=np.nan, FNR=np.nan, PPR=np.nan)\n",
        "    TP = int(((yp == 1) & (yt == 1)).sum())\n",
        "    FP = int(((yp == 1) & (yt == 0)).sum())\n",
        "    TN = int(((yp == 0) & (yt == 0)).sum())\n",
        "    FN = int(((yp == 0) & (yt == 1)).sum())\n",
        "    TPR = safe_div(TP, TP + FN)\n",
        "    FPR = safe_div(FP, FP + TN)\n",
        "    FNR = safe_div(FN, TP + FN)\n",
        "    PPR = safe_div((yp == 1).sum(), yp.size)\n",
        "    return dict(TP=TP, FP=FP, TN=TN, FN=FN, TPR=TPR, FPR=FPR, FNR=FNR, PPR=PPR)\n",
        "\n",
        "def score_by_group(y_score, group_mask):\n",
        "    ys = y_score[group_mask]\n",
        "    if ys.size == 0:\n",
        "        return np.nan\n",
        "    return float(np.mean(ys))\n",
        "\n",
        "def wilcoxon_paired_zero_center(diffs):\n",
        "    diffs = np.array(diffs, dtype=float)\n",
        "    diffs = diffs[~np.isnan(diffs)]\n",
        "    if diffs.size == 0:\n",
        "        return None\n",
        "    if np.allclose(diffs, 0.0):\n",
        "        return 1.0\n",
        "    try:\n",
        "        stat, p = wilcoxon(\n",
        "            diffs, zero_method=\"wilcox\", alternative=\"two-sided\",\n",
        "            correction=False, mode=\"exact\" if diffs.size <= 25 else \"approx\"\n",
        "        )\n",
        "        return float(p)\n",
        "    except Exception:\n",
        "        try:\n",
        "            stat, p = wilcoxon(\n",
        "                diffs, zero_method=\"wilcox\", alternative=\"two-sided\",\n",
        "                correction=False, mode=\"approx\"\n",
        "            )\n",
        "            return float(p)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "def load_d7(cfg):\n",
        "    log(\"📥 Loading D7 …\")\n",
        "    t0 = time.time()\n",
        "    df = pd.read_csv(cfg[\"path\"])\n",
        "    log(f\"✅ Loaded shape: {df.shape} (took {time.time()-t0:.2f}s)\")\n",
        "    before = df[cfg[\"gender_col\"]].unique()\n",
        "    df[cfg[\"gender_col\"]] = df[cfg[\"gender_col\"]].map(cfg[\"gender_map\"])\n",
        "    after = df[cfg[\"gender_col\"]].unique()\n",
        "    log(f\"↪️  Mapped gender {before} -> {after}\")\n",
        "    df[cfg[\"label_col\"]] = (df[cfg[\"label_col\"]].astype(float) > 0).astype(int)\n",
        "    df = df.dropna(subset=[cfg[\"gender_col\"], cfg[\"label_col\"]]).copy()\n",
        "    df = df[df[cfg[\"gender_col\"]].isin([0, 1])]\n",
        "    df = df[df[cfg[\"label_col\"]].isin([0, 1])]\n",
        "    df = df.dropna(axis=0, how=\"any\")\n",
        "    log(f\"🧹 Cleaned shape: {df.shape}\")\n",
        "    return df\n",
        "\n",
        "def split_X_y_g(df, gender_col, label_col):\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    feat_cols = [c for c in num_cols if c not in {gender_col, label_col}]\n",
        "    X = df[feat_cols].values\n",
        "    y = df[label_col].values.astype(int)\n",
        "    g = df[gender_col].values.astype(int)\n",
        "    return X, y, g, feat_cols\n",
        "\n",
        "# ===========================\n",
        "# Base models and mitigators\n",
        "# ===========================\n",
        "def base_models():\n",
        "    return {\n",
        "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "        \"LR\": LogisticRegression(max_iter=2000, random_state=RANDOM_STATE),\n",
        "        \"DT\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "        \"RF\": RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=RANDOM_STATE),\n",
        "        \"SVM\": LinearSVC(C=1.0, max_iter=5000, random_state=RANDOM_STATE)\n",
        "    }\n",
        "\n",
        "def fairness_wrappers():\n",
        "    \"\"\"\n",
        "    - For LR/DT/RF/SVM: ExponentiatedGradient(DemographicParity) (in-processing)\n",
        "    - For KNN: ThresholdOptimizer (post-processing, since KNN lacks sample_weight)\n",
        "    \"\"\"\n",
        "    def eg_wrap(est):\n",
        "        return ExponentiatedGradient(\n",
        "            estimator=est,\n",
        "            constraints=DemographicParity(),\n",
        "            max_iter=50,\n",
        "            nu=1e-6\n",
        "        )\n",
        "    def to_wrap(prefit_est):\n",
        "        return ThresholdOptimizer(\n",
        "            estimator=prefit_est,\n",
        "            constraints=\"demographic_parity\",\n",
        "            predict_method=\"auto\",\n",
        "            prefit=True\n",
        "        )\n",
        "    return eg_wrap, to_wrap\n",
        "\n",
        "# ===========================\n",
        "# Fairness-aware CV and Wilcoxon p-values (with progress)\n",
        "# ===========================\n",
        "def evaluate_fairlearn_dp_verbose(X, y, g):\n",
        "    log(\"🔹 Starting fairness-aware evaluation (Demographic Parity)\")\n",
        "    scaler = StandardScaler()\n",
        "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
        "    models = base_models()\n",
        "    eg_wrap, to_wrap = fairness_wrappers()\n",
        "\n",
        "    collectors = {name: {\n",
        "        \"dp_diff\": [], \"eo_tpr_diff\": [], \"eo_fpr_diff\": [],\n",
        "        \"eopp_tpr_diff\": [], \"fpr_par_diff\": [],\n",
        "        \"te_log_ratio_diff\": [], \"ds_score_diff\": [],\n",
        "        \"di_log_ratio\": [], \"ber_diff\": []\n",
        "    } for name in models.keys()}\n",
        "\n",
        "    for fold, (tr, te) in enumerate(skf.split(X, y), start=1):\n",
        "        log(f\"\\n👉 Fold {fold}/{N_SPLITS} — preparing data\")\n",
        "        t_fold = time.time()\n",
        "        Xtr, Xte = X[tr], X[te]\n",
        "        ytr, yte = y[tr], y[te]\n",
        "        gtr, gte = g[tr], g[te]\n",
        "\n",
        "        t0 = time.time()\n",
        "        Xtr = scaler.fit_transform(Xtr)\n",
        "        Xte = scaler.transform(Xte)\n",
        "        log(f\"   ✨ Scaled features (took {time.time()-t0:.2f}s)\")\n",
        "\n",
        "        female_mask = (gte == 0)\n",
        "        male_mask   = (gte == 1)\n",
        "\n",
        "        for name, base in models.items():\n",
        "            log(f\"   ⏳ Training {name} with fairness constraints …\")\n",
        "            t_train = time.time()\n",
        "\n",
        "            if name == \"KNN\":\n",
        "                # Post-processing DP for KNN (requires sensitive_features at fit & predict)\n",
        "                base_knn = KNeighborsClassifier(n_neighbors=base.n_neighbors)\n",
        "                base_knn.fit(Xtr, ytr)\n",
        "                mitigator = to_wrap(base_knn)\n",
        "                mitigator.fit(Xtr, ytr, sensitive_features=gtr)\n",
        "            else:\n",
        "                # In-processing DP via ExponentiatedGradient\n",
        "                base_est = base.__class__(**base.get_params())\n",
        "                mitigator = eg_wrap(base_est)\n",
        "                mitigator.fit(Xtr, ytr, sensitive_features=gtr)\n",
        "\n",
        "            log(f\"   ✅ {name} fitted in {time.time()-t_train:.2f}s\")\n",
        "\n",
        "            t_pred = time.time()\n",
        "            if name == \"KNN\":\n",
        "                # IMPORTANT: ThresholdOptimizer.predict REQUIRES sensitive_features\n",
        "                y_pred = mitigator.predict(Xte, sensitive_features=gte)\n",
        "            else:\n",
        "                y_pred = mitigator.predict(Xte)\n",
        "            log(f\"   🔍 {name} predictions in {time.time()-t_pred:.2f}s\")\n",
        "\n",
        "            # Scores for discrimination score\n",
        "            t_score = time.time()\n",
        "            if hasattr(mitigator, \"predict_proba\"):\n",
        "                try:\n",
        "                    y_score = mitigator.predict_proba(Xte)[:, 1]\n",
        "                except Exception:\n",
        "                    y_score = y_pred.astype(float)\n",
        "            else:\n",
        "                if hasattr(mitigator, \"decision_function\"):\n",
        "                    dfun = mitigator.decision_function(Xte)\n",
        "                    mn, mx = np.min(dfun), np.max(dfun)\n",
        "                    y_score = (dfun - mn) / (mx - mn + 1e-12)\n",
        "                else:\n",
        "                    if name == \"KNN\" and hasattr(mitigator.estimator_, \"predict_proba\"):\n",
        "                        y_score = mitigator.estimator_.predict_proba(Xte)[:, 1]\n",
        "                    else:\n",
        "                        y_score = y_pred.astype(float)\n",
        "            log(f\"   🧮 {name} scoring prepared in {time.time()-t_score:.2f}s\")\n",
        "\n",
        "            gf = confusion_by_group(yte, y_pred, female_mask)\n",
        "            gm = confusion_by_group(yte, y_pred, male_mask)\n",
        "\n",
        "            ppr_f, ppr_m = gf[\"PPR\"], gm[\"PPR\"]\n",
        "            tpr_f, tpr_m = gf[\"TPR\"], gm[\"TPR\"]\n",
        "            fpr_f, fpr_m = gf[\"FPR\"], gm[\"FPR\"]\n",
        "            fnr_f, fnr_m = gf[\"FNR\"], gm[\"FNR\"]\n",
        "\n",
        "            eopp_diff = (tpr_f - tpr_m) if (not np.isnan(tpr_f) and not np.isnan(tpr_m)) else np.nan\n",
        "            ratio_f = safe_div(fnr_f, fpr_f) if (not np.isnan(fnr_f) and not np.isnan(fpr_f)) else np.nan\n",
        "            ratio_m = safe_div(fnr_m, fpr_m) if (not np.isnan(fnr_m) and not np.isnan(fpr_m)) else np.nan\n",
        "            te_log_ratio_diff = np.nan\n",
        "            if not np.isnan(ratio_f) and not np.isnan(ratio_m) and ratio_f and ratio_m:\n",
        "                te_log_ratio_diff = np.log(ratio_f + 1e-12) - np.log(ratio_m + 1e-12)\n",
        "\n",
        "            ds_diff = score_by_group(y_score, female_mask) - score_by_group(y_score, male_mask)\n",
        "            di_lr = np.nan\n",
        "            if not np.isnan(ppr_f) and not np.isnan(ppr_m) and ppr_f and ppr_m:\n",
        "                di_lr = np.log((ppr_f + 1e-12) / (ppr_m + 1e-12))\n",
        "\n",
        "            ber_f = np.nanmean([fnr_f, fpr_f])\n",
        "            ber_m = np.nanmean([fnr_m, fpr_m])\n",
        "            ber_diff = ber_f - ber_m if (not np.isnan(ber_f) and not np.isnan(ber_m)) else np.nan\n",
        "\n",
        "            collectors[name][\"dp_diff\"].append((ppr_f - ppr_m) if (not np.isnan(ppr_f) and not np.isnan(ppr_m)) else np.nan)\n",
        "            collectors[name][\"eo_tpr_diff\"].append((tpr_f - tpr_m) if (not np.isnan(tpr_f) and not np.isnan(tpr_m)) else np.nan)\n",
        "            collectors[name][\"eo_fpr_diff\"].append((fpr_f - fpr_m) if (not np.isnan(fpr_f) and not np.isnan(fpr_m)) else np.nan)\n",
        "            collectors[name][\"eopp_tpr_diff\"].append(eopp_diff)\n",
        "            collectors[name][\"fpr_par_diff\"].append((fpr_f - fpr_m) if (not np.isnan(fpr_f) and not np.isnan(fpr_m)) else np.nan)\n",
        "            collectors[name][\"te_log_ratio_diff\"].append(te_log_ratio_diff)\n",
        "            collectors[name][\"ds_score_diff\"].append(ds_diff)\n",
        "            collectors[name][\"di_log_ratio\"].append(di_lr)\n",
        "            collectors[name][\"ber_diff\"].append(ber_diff)\n",
        "\n",
        "        log(f\"📦 Completed fold {fold} in {time.time()-t_fold:.2f}s\")\n",
        "\n",
        "    log(\"\\n🧮 Calculating Wilcoxon p-values across folds …\")\n",
        "    out = {}\n",
        "    for name, vals in collectors.items():\n",
        "        t_p = time.time()\n",
        "        dp_p     = wilcoxon_paired_zero_center(vals[\"dp_diff\"])\n",
        "        eo_tpr_p = wilcoxon_paired_zero_center(vals[\"eo_tpr_diff\"])\n",
        "        eo_fpr_p = wilcoxon_paired_zero_center(vals[\"eo_fpr_diff\"])\n",
        "        eopp_p   = wilcoxon_paired_zero_center(vals[\"eopp_tpr_diff\"])\n",
        "        fpr_p    = wilcoxon_paired_zero_center(vals[\"fpr_par_diff\"])\n",
        "        te_p     = wilcoxon_paired_zero_center(vals[\"te_log_ratio_diff\"])\n",
        "        ds_p     = wilcoxon_paired_zero_center(vals[\"ds_score_diff\"])\n",
        "        di_p     = wilcoxon_paired_zero_center(vals[\"di_log_ratio\"])\n",
        "        ber_p    = wilcoxon_paired_zero_center(vals[\"ber_diff\"])\n",
        "        log(f\"   ➡️ {name} p-values computed in {time.time()-t_p:.2f}s\")\n",
        "\n",
        "        out[name] = {\n",
        "            \"Demographic parity\": fmt_p(dp_p),\n",
        "            \"Equalised odds\": f\"TPR={fmt_p(eo_tpr_p)}, FPR={fmt_p(eo_fpr_p)}\",\n",
        "            \"Equal opportunity\": fmt_p(eopp_p),\n",
        "            \"False positive rate parity\": fmt_p(fpr_p),\n",
        "            \"Treatment equality\": fmt_p(te_p),\n",
        "            \"Discrimination score\": fmt_p(ds_p),\n",
        "            \"Disparate Impact\": fmt_p(di_p),\n",
        "            \"Balanced Error Rate\": fmt_p(ber_p),\n",
        "        }\n",
        "    log(\"✅ Finished fairness-aware evaluation.\")\n",
        "    return out\n",
        "\n",
        "def build_table(pvalues_map):\n",
        "    fairness_rows = [\n",
        "        \"Demographic parity\",\n",
        "        \"Equalised odds\",\n",
        "        \"Equal opportunity\",\n",
        "        \"False positive rate parity\",\n",
        "        \"Treatment equality\",\n",
        "        \"Discrimination score\",\n",
        "        \"Disparate Impact\",\n",
        "        \"Balanced Error Rate\",\n",
        "    ]\n",
        "    model_names = list(pvalues_map.keys())\n",
        "    data = {m: [pvalues_map[m][row] for row in fairness_rows] for m in model_names}\n",
        "    return pd.DataFrame(data, index=fairness_rows)\n",
        "\n",
        "# ===========================\n",
        "# Run (D7 only)\n",
        "# ===========================\n",
        "def main():\n",
        "    df = load_d7(D7_CFG)\n",
        "    X, y, g, feats = split_X_y_g(df, D7_CFG[\"gender_col\"], D7_CFG[\"label_col\"])\n",
        "    log(f\"🔹 Features: {len(feats)} | Labels: {np.bincount(y)} | Gender groups: {np.bincount(g)}\")\n",
        "\n",
        "    pvals = evaluate_fairlearn_dp_verbose(X, y, g)\n",
        "    table = build_table(pvals)\n",
        "\n",
        "    print(\"\\n📑 Fairness-aware (Demographic Parity) – Wilcoxon p-values table for D7\")\n",
        "    print(table.to_string())\n",
        "    table.to_csv(\"D7_fairlearn_DP_pvalues_verbose.csv\")\n",
        "    log(\"💾 Saved CSV: D7_fairlearn_DP_pvalues_verbose.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "uEZzP36eg1CG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07cde8a2-e69a-4ea9-c0a2-b8da45239d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:09:04] 📥 Loading D7 …\n",
            "[02:09:04] ✅ Loaded shape: (70000, 14) (took 0.17s)\n",
            "[02:09:04] ↪️  Mapped gender [2 1] -> [0 1]\n",
            "[02:09:04] 🧹 Cleaned shape: (70000, 14)\n",
            "[02:09:04] 🔹 Features: 12 | Labels: [35021 34979] | Gender groups: [24470 45530]\n",
            "[02:09:04] 🔹 Starting fairness-aware evaluation (Demographic Parity)\n",
            "[02:09:04] \n",
            "👉 Fold 1/10 — preparing data\n",
            "[02:09:04]    ✨ Scaled features (took 0.02s)\n",
            "[02:09:04]    ⏳ Training KNN with fairness constraints …\n",
            "[02:09:37]    ✅ KNN fitted in 32.59s\n",
            "[02:09:39]    🔍 KNN predictions in 2.70s\n",
            "[02:09:42]    🧮 KNN scoring prepared in 2.63s\n",
            "[02:09:42]    ⏳ Training LR with fairness constraints …\n",
            "[02:09:56]    ✅ LR fitted in 14.01s\n",
            "[02:09:56]    🔍 LR predictions in 0.02s\n",
            "[02:09:56]    🧮 LR scoring prepared in 0.00s\n",
            "[02:09:56]    ⏳ Training DT with fairness constraints …\n",
            "[02:10:18]    ✅ DT fitted in 21.68s\n",
            "[02:10:18]    🔍 DT predictions in 0.01s\n",
            "[02:10:18]    🧮 DT scoring prepared in 0.00s\n",
            "[02:10:18]    ⏳ Training RF with fairness constraints …\n",
            "[02:21:14]    ✅ RF fitted in 656.22s\n",
            "[02:21:14]    🔍 RF predictions in 0.36s\n",
            "[02:21:14]    🧮 RF scoring prepared in 0.00s\n",
            "[02:21:14]    ⏳ Training SVM with fairness constraints …\n",
            "[02:21:17]    ✅ SVM fitted in 2.75s\n",
            "[02:21:17]    🔍 SVM predictions in 0.01s\n",
            "[02:21:17]    🧮 SVM scoring prepared in 0.00s\n",
            "[02:21:17] 📦 Completed fold 1 in 733.04s\n",
            "[02:21:17] \n",
            "👉 Fold 2/10 — preparing data\n",
            "[02:21:17]    ✨ Scaled features (took 0.04s)\n",
            "[02:21:17]    ⏳ Training KNN with fairness constraints …\n",
            "[02:21:42]    ✅ KNN fitted in 24.85s\n",
            "[02:21:46]    🔍 KNN predictions in 3.73s\n",
            "[02:21:48]    🧮 KNN scoring prepared in 2.63s\n",
            "[02:21:48]    ⏳ Training LR with fairness constraints …\n",
            "[02:21:58]    ✅ LR fitted in 9.87s\n",
            "[02:21:58]    🔍 LR predictions in 0.01s\n",
            "[02:21:58]    🧮 LR scoring prepared in 0.00s\n",
            "[02:21:58]    ⏳ Training DT with fairness constraints …\n",
            "[02:22:20]    ✅ DT fitted in 21.71s\n",
            "[02:22:20]    🔍 DT predictions in 0.01s\n",
            "[02:22:20]    🧮 DT scoring prepared in 0.00s\n",
            "[02:22:20]    ⏳ Training RF with fairness constraints …\n",
            "[02:33:23]    ✅ RF fitted in 662.71s\n",
            "[02:33:23]    🔍 RF predictions in 0.35s\n",
            "[02:33:23]    🧮 RF scoring prepared in 0.00s\n",
            "[02:33:23]    ⏳ Training SVM with fairness constraints …\n",
            "[02:33:27]    ✅ SVM fitted in 3.97s\n",
            "[02:33:27]    🔍 SVM predictions in 0.01s\n",
            "[02:33:27]    🧮 SVM scoring prepared in 0.00s\n",
            "[02:33:27] 📦 Completed fold 2 in 729.93s\n",
            "[02:33:27] \n",
            "👉 Fold 3/10 — preparing data\n",
            "[02:33:27]    ✨ Scaled features (took 0.02s)\n",
            "[02:33:27]    ⏳ Training KNN with fairness constraints …\n",
            "[02:33:51]    ✅ KNN fitted in 23.98s\n",
            "[02:33:55]    🔍 KNN predictions in 3.59s\n",
            "[02:33:57]    🧮 KNN scoring prepared in 2.54s\n",
            "[02:33:57]    ⏳ Training LR with fairness constraints …\n",
            "[02:34:08]    ✅ LR fitted in 10.90s\n",
            "[02:34:08]    🔍 LR predictions in 0.01s\n",
            "[02:34:08]    🧮 LR scoring prepared in 0.00s\n",
            "[02:34:08]    ⏳ Training DT with fairness constraints …\n",
            "[02:34:30]    ✅ DT fitted in 21.71s\n",
            "[02:34:30]    🔍 DT predictions in 0.01s\n",
            "[02:34:30]    🧮 DT scoring prepared in 0.00s\n",
            "[02:34:30]    ⏳ Training RF with fairness constraints …\n",
            "[02:45:26]    ✅ RF fitted in 656.50s\n",
            "[02:45:27]    🔍 RF predictions in 0.35s\n",
            "[02:45:27]    🧮 RF scoring prepared in 0.00s\n",
            "[02:45:27]    ⏳ Training SVM with fairness constraints …\n",
            "[02:45:30]    ✅ SVM fitted in 3.26s\n",
            "[02:45:30]    🔍 SVM predictions in 0.00s\n",
            "[02:45:30]    🧮 SVM scoring prepared in 0.00s\n",
            "[02:45:30] 📦 Completed fold 3 in 722.93s\n",
            "[02:45:30] \n",
            "👉 Fold 4/10 — preparing data\n",
            "[02:45:30]    ✨ Scaled features (took 0.03s)\n",
            "[02:45:30]    ⏳ Training KNN with fairness constraints …\n",
            "[02:45:55]    ✅ KNN fitted in 24.91s\n",
            "[02:45:58]    🔍 KNN predictions in 2.68s\n",
            "[02:46:00]    🧮 KNN scoring prepared in 2.76s\n",
            "[02:46:00]    ⏳ Training LR with fairness constraints …\n",
            "[02:46:10]    ✅ LR fitted in 9.88s\n",
            "[02:46:10]    🔍 LR predictions in 0.00s\n",
            "[02:46:10]    🧮 LR scoring prepared in 0.00s\n",
            "[02:46:10]    ⏳ Training DT with fairness constraints …\n",
            "[02:46:32]    ✅ DT fitted in 21.76s\n",
            "[02:46:32]    🔍 DT predictions in 0.01s\n",
            "[02:46:32]    🧮 DT scoring prepared in 0.00s\n",
            "[02:46:32]    ⏳ Training RF with fairness constraints …\n",
            "[02:57:25]    ✅ RF fitted in 653.13s\n",
            "[02:57:26]    🔍 RF predictions in 0.35s\n",
            "[02:57:26]    🧮 RF scoring prepared in 0.00s\n",
            "[02:57:26]    ⏳ Training SVM with fairness constraints …\n",
            "[02:57:29]    ✅ SVM fitted in 3.21s\n",
            "[02:57:29]    🔍 SVM predictions in 0.00s\n",
            "[02:57:29]    🧮 SVM scoring prepared in 0.00s\n",
            "[02:57:29] 📦 Completed fold 4 in 718.76s\n",
            "[02:57:29] \n",
            "👉 Fold 5/10 — preparing data\n",
            "[02:57:29]    ✨ Scaled features (took 0.03s)\n",
            "[02:57:29]    ⏳ Training KNN with fairness constraints …\n",
            "[02:57:52]    ✅ KNN fitted in 23.34s\n",
            "[02:57:55]    🔍 KNN predictions in 2.41s\n",
            "[02:57:58]    🧮 KNN scoring prepared in 3.18s\n",
            "[02:57:58]    ⏳ Training LR with fairness constraints …\n",
            "[02:58:08]    ✅ LR fitted in 10.67s\n",
            "[02:58:08]    🔍 LR predictions in 0.01s\n",
            "[02:58:08]    🧮 LR scoring prepared in 0.00s\n",
            "[02:58:08]    ⏳ Training DT with fairness constraints …\n",
            "[02:58:30]    ✅ DT fitted in 21.84s\n",
            "[02:58:30]    🔍 DT predictions in 0.01s\n",
            "[02:58:30]    🧮 DT scoring prepared in 0.00s\n",
            "[02:58:30]    ⏳ Training RF with fairness constraints …\n",
            "[03:09:25]    ✅ RF fitted in 654.73s\n",
            "[03:09:25]    🔍 RF predictions in 0.35s\n",
            "[03:09:25]    🧮 RF scoring prepared in 0.00s\n",
            "[03:09:25]    ⏳ Training SVM with fairness constraints …\n",
            "[03:09:30]    ✅ SVM fitted in 4.34s\n",
            "[03:09:30]    🔍 SVM predictions in 0.00s\n",
            "[03:09:30]    🧮 SVM scoring prepared in 0.00s\n",
            "[03:09:30] 📦 Completed fold 5 in 720.95s\n",
            "[03:09:30] \n",
            "👉 Fold 6/10 — preparing data\n",
            "[03:09:30]    ✨ Scaled features (took 0.03s)\n",
            "[03:09:30]    ⏳ Training KNN with fairness constraints …\n",
            "[03:09:55]    ✅ KNN fitted in 24.83s\n",
            "[03:09:57]    🔍 KNN predictions in 2.68s\n",
            "[03:10:00]    🧮 KNN scoring prepared in 2.68s\n",
            "[03:10:00]    ⏳ Training LR with fairness constraints …\n",
            "[03:10:11]    ✅ LR fitted in 10.63s\n",
            "[03:10:11]    🔍 LR predictions in 0.01s\n",
            "[03:10:11]    🧮 LR scoring prepared in 0.00s\n",
            "[03:10:11]    ⏳ Training DT with fairness constraints …\n",
            "[03:10:32]    ✅ DT fitted in 21.89s\n",
            "[03:10:32]    🔍 DT predictions in 0.01s\n",
            "[03:10:32]    🧮 DT scoring prepared in 0.00s\n",
            "[03:10:32]    ⏳ Training RF with fairness constraints …\n",
            "[03:21:28]    ✅ RF fitted in 655.75s\n",
            "[03:21:29]    🔍 RF predictions in 0.36s\n",
            "[03:21:29]    🧮 RF scoring prepared in 0.00s\n",
            "[03:21:29]    ⏳ Training SVM with fairness constraints …\n",
            "[03:21:32]    ✅ SVM fitted in 3.28s\n",
            "[03:21:32]    🔍 SVM predictions in 0.00s\n",
            "[03:21:32]    🧮 SVM scoring prepared in 0.00s\n",
            "[03:21:32] 📦 Completed fold 6 in 722.19s\n",
            "[03:21:32] \n",
            "👉 Fold 7/10 — preparing data\n",
            "[03:21:32]    ✨ Scaled features (took 0.03s)\n",
            "[03:21:32]    ⏳ Training KNN with fairness constraints …\n",
            "[03:21:56]    ✅ KNN fitted in 23.64s\n",
            "[03:21:58]    🔍 KNN predictions in 2.65s\n",
            "[03:22:02]    🧮 KNN scoring prepared in 3.46s\n",
            "[03:22:02]    ⏳ Training LR with fairness constraints …\n",
            "[03:22:17]    ✅ LR fitted in 15.35s\n",
            "[03:22:17]    🔍 LR predictions in 0.01s\n",
            "[03:22:17]    🧮 LR scoring prepared in 0.00s\n",
            "[03:22:17]    ⏳ Training DT with fairness constraints …\n",
            "[03:22:38]    ✅ DT fitted in 21.22s\n",
            "[03:22:38]    🔍 DT predictions in 0.01s\n",
            "[03:22:38]    🧮 DT scoring prepared in 0.00s\n",
            "[03:22:38]    ⏳ Training RF with fairness constraints …\n",
            "[03:33:38]    ✅ RF fitted in 659.36s\n",
            "[03:33:38]    🔍 RF predictions in 0.35s\n",
            "[03:33:38]    🧮 RF scoring prepared in 0.00s\n",
            "[03:33:38]    ⏳ Training SVM with fairness constraints …\n",
            "[03:33:41]    ✅ SVM fitted in 3.35s\n",
            "[03:33:41]    🔍 SVM predictions in 0.00s\n",
            "[03:33:41]    🧮 SVM scoring prepared in 0.00s\n",
            "[03:33:41] 📦 Completed fold 7 in 729.47s\n",
            "[03:33:41] \n",
            "👉 Fold 8/10 — preparing data\n",
            "[03:33:41]    ✨ Scaled features (took 0.03s)\n",
            "[03:33:41]    ⏳ Training KNN with fairness constraints …\n",
            "[03:34:05]    ✅ KNN fitted in 23.36s\n",
            "[03:34:07]    🔍 KNN predictions in 2.46s\n",
            "[03:34:11]    🧮 KNN scoring prepared in 3.50s\n",
            "[03:34:11]    ⏳ Training LR with fairness constraints …\n",
            "[03:34:18]    ✅ LR fitted in 7.12s\n",
            "[03:34:18]    🔍 LR predictions in 0.01s\n",
            "[03:34:18]    🧮 LR scoring prepared in 0.00s\n",
            "[03:34:18]    ⏳ Training DT with fairness constraints …\n",
            "[03:34:40]    ✅ DT fitted in 22.17s\n",
            "[03:34:40]    🔍 DT predictions in 0.01s\n",
            "[03:34:40]    🧮 DT scoring prepared in 0.00s\n",
            "[03:34:40]    ⏳ Training RF with fairness constraints …\n",
            "[03:45:39]    ✅ RF fitted in 658.73s\n",
            "[03:45:39]    🔍 RF predictions in 0.58s\n",
            "[03:45:39]    🧮 RF scoring prepared in 0.00s\n",
            "[03:45:39]    ⏳ Training SVM with fairness constraints …\n",
            "[03:45:44]    ✅ SVM fitted in 4.55s\n",
            "[03:45:44]    🔍 SVM predictions in 0.00s\n",
            "[03:45:44]    🧮 SVM scoring prepared in 0.00s\n",
            "[03:45:44] 📦 Completed fold 8 in 722.58s\n",
            "[03:45:44] \n",
            "👉 Fold 9/10 — preparing data\n",
            "[03:45:44]    ✨ Scaled features (took 0.03s)\n",
            "[03:45:44]    ⏳ Training KNN with fairness constraints …\n",
            "[03:46:09]    ✅ KNN fitted in 24.84s\n",
            "[03:46:11]    🔍 KNN predictions in 2.57s\n",
            "[03:46:14]    🧮 KNN scoring prepared in 2.62s\n",
            "[03:46:14]    ⏳ Training LR with fairness constraints …\n",
            "[03:46:24]    ✅ LR fitted in 9.57s\n",
            "[03:46:24]    🔍 LR predictions in 0.00s\n",
            "[03:46:24]    🧮 LR scoring prepared in 0.00s\n",
            "[03:46:24]    ⏳ Training DT with fairness constraints …\n",
            "[03:46:45]    ✅ DT fitted in 21.88s\n",
            "[03:46:45]    🔍 DT predictions in 0.01s\n",
            "[03:46:45]    🧮 DT scoring prepared in 0.00s\n",
            "[03:46:45]    ⏳ Training RF with fairness constraints …\n",
            "[03:57:44]    ✅ RF fitted in 658.04s\n",
            "[03:57:44]    🔍 RF predictions in 0.38s\n",
            "[03:57:44]    🧮 RF scoring prepared in 0.00s\n",
            "[03:57:44]    ⏳ Training SVM with fairness constraints …\n",
            "[03:57:47]    ✅ SVM fitted in 2.85s\n",
            "[03:57:47]    🔍 SVM predictions in 0.00s\n",
            "[03:57:47]    🧮 SVM scoring prepared in 0.00s\n",
            "[03:57:47] 📦 Completed fold 9 in 722.84s\n",
            "[03:57:47] \n",
            "👉 Fold 10/10 — preparing data\n",
            "[03:57:47]    ✨ Scaled features (took 0.03s)\n",
            "[03:57:47]    ⏳ Training KNN with fairness constraints …\n",
            "[03:58:12]    ✅ KNN fitted in 25.21s\n",
            "[03:58:16]    🔍 KNN predictions in 3.61s\n",
            "[03:58:18]    🧮 KNN scoring prepared in 2.78s\n",
            "[03:58:18]    ⏳ Training LR with fairness constraints …\n",
            "[03:58:29]    ✅ LR fitted in 10.94s\n",
            "[03:58:29]    🔍 LR predictions in 0.01s\n",
            "[03:58:29]    🧮 LR scoring prepared in 0.00s\n",
            "[03:58:29]    ⏳ Training DT with fairness constraints …\n",
            "[03:58:51]    ✅ DT fitted in 21.62s\n",
            "[03:58:51]    🔍 DT predictions in 0.01s\n",
            "[03:58:51]    🧮 DT scoring prepared in 0.00s\n",
            "[03:58:51]    ⏳ Training RF with fairness constraints …\n",
            "[04:09:52]    ✅ RF fitted in 660.84s\n",
            "[04:09:52]    🔍 RF predictions in 0.37s\n",
            "[04:09:52]    🧮 RF scoring prepared in 0.00s\n",
            "[04:09:52]    ⏳ Training SVM with fairness constraints …\n",
            "[04:09:56]    ✅ SVM fitted in 3.55s\n",
            "[04:09:56]    🔍 SVM predictions in 0.00s\n",
            "[04:09:56]    🧮 SVM scoring prepared in 0.00s\n",
            "[04:09:56] 📦 Completed fold 10 in 729.00s\n",
            "[04:09:56] \n",
            "🧮 Calculating Wilcoxon p-values across folds …\n",
            "[04:09:56]    ➡️ KNN p-values computed in 0.02s\n",
            "[04:09:56]    ➡️ LR p-values computed in 0.01s\n",
            "[04:09:56]    ➡️ DT p-values computed in 0.02s\n",
            "[04:09:56]    ➡️ RF p-values computed in 0.01s\n",
            "[04:09:56]    ➡️ SVM p-values computed in 0.01s\n",
            "[04:09:56] ✅ Finished fairness-aware evaluation.\n",
            "\n",
            "📑 Fairness-aware (Demographic Parity) – Wilcoxon p-values table for D7\n",
            "                                               KNN            LR                      DT                      RF           SVM\n",
            "Demographic parity                               …             …                  0.0039                  0.0098             …\n",
            "Equalised odds              TPR=0.0098, FPR=0.0371  TPR=…, FPR=…  TPR=0.0273, FPR=0.0371  TPR=0.0488, FPR=0.0273  TPR=…, FPR=…\n",
            "Equal opportunity                           0.0098             …                  0.0273                  0.0488             …\n",
            "False positive rate parity                  0.0371             …                  0.0371                  0.0273             …\n",
            "Treatment equality                               …             …                  0.0020                  0.0098             …\n",
            "Discrimination score                             …             …                  0.0039                  0.0098             …\n",
            "Disparate Impact                                 …             …                  0.0039                  0.0098             …\n",
            "Balanced Error Rate                         0.0059             …                       …                       …             …\n",
            "[04:09:56] 💾 Saved CSV: D7_fairlearn_DP_pvalues_verbose.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fairness-Aware ML Evaluation Pipeline (Full Script with p-values)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        ")\n",
        "from scipy.stats import wasserstein_distance\n",
        "import warnings\n",
        "\n",
        "# --- Setup ---\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# === Load and clean dataset ===\n",
        "dataset = pd.read_csv('framingham.csv').dropna()\n",
        "\n",
        "# --- Simple bias mitigation example (as given): remove 100 male-positive instances ---\n",
        "male_chd = dataset[(dataset['male'] == 1) & (dataset['TenYearCHD'] == 1)]\n",
        "if len(male_chd) >= 100:\n",
        "    dataset = dataset.drop(male_chd.sample(n=100, random_state=seed).index)\n",
        "\n",
        "# === Prepare data ===\n",
        "y = dataset['TenYearCHD'].values\n",
        "X = dataset.drop('TenYearCHD', axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Gender masks\n",
        "male_mask = dataset['male'] == 1\n",
        "female_mask = ~male_mask\n",
        "X_male, X_female = X_scaled[male_mask], X_scaled[female_mask]\n",
        "y_male, y_female = y[male_mask], y[female_mask]\n",
        "\n",
        "# === Define models ===\n",
        "models = {\n",
        "    'SVM': SVC(probability=True, random_state=seed),\n",
        "    'LR': LogisticRegression(random_state=seed, max_iter=1000),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'RF': RandomForestClassifier(random_state=seed),\n",
        "    'DT': DecisionTreeClassifier(random_state=seed),\n",
        "    'ANN': MLPClassifier(random_state=seed, max_iter=500)\n",
        "}\n",
        "\n",
        "# === Metric calculation helpers ===\n",
        "def compute_metrics(y_true, y_pred, y_prob=None):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    if cm.size == 4:\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "    else:\n",
        "        TN = FP = FN = TP = 0\n",
        "    res = {\n",
        "        'TPR': TP / (TP + FN) if (TP + FN) > 0 else 0.0,\n",
        "        'TNR': TN / (TN + FP) if (TN + FP) > 0 else 0.0,\n",
        "        'FPR': FP / (FP + TN) if (FP + TN) > 0 else 0.0,\n",
        "        'FNR': FN / (TP + FN) if (TP + FN) > 0 else 0.0,\n",
        "        'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN,\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "        'F1': f1_score(y_true, y_pred, zero_division=0),\n",
        "    }\n",
        "    if y_prob is not None:\n",
        "        try:\n",
        "            res['ROC_AUC'] = roc_auc_score(y_true, y_prob)\n",
        "        except Exception:\n",
        "            res['ROC_AUC'] = np.nan\n",
        "    else:\n",
        "        res['ROC_AUC'] = np.nan\n",
        "    return res\n",
        "\n",
        "# === Group-wise k-fold experiments (original idea, per gender) ===\n",
        "def run_kfold(X_arr, y_arr, label, n_splits=20, random_state=seed):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    rows = []\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_arr), start=1):\n",
        "        X_train, X_test = X_arr[train_idx], X_arr[test_idx]\n",
        "        y_train, y_test = y_arr[train_idx], y_arr[test_idx]\n",
        "\n",
        "        fold_result = {'Fold': fold, 'Group': label}\n",
        "        for name, model in models.items():\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            y_prob = None\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                y_prob = model.predict_proba(X_test)[:, 1]\n",
        "            elif hasattr(model, \"decision_function\"):\n",
        "                z = model.decision_function(X_test)\n",
        "                y_prob = 1/(1+np.exp(-z))\n",
        "\n",
        "            scores = compute_metrics(y_test, y_pred, y_prob=y_prob)\n",
        "            for k, v in scores.items():\n",
        "                fold_result[f\"{name}_{k}\"] = v\n",
        "        rows.append(fold_result)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "print(\"Running Female Group (20-fold)\")\n",
        "female_df = run_kfold(X_female, y_female, 'Female', n_splits=20, random_state=seed)\n",
        "print(\"Running Male Group (20-fold)\")\n",
        "male_df   = run_kfold(X_male, y_male, 'Male', n_splits=20, random_state=seed)\n",
        "group_kfold_df = pd.concat([female_df, male_df], ignore_index=True)\n",
        "\n",
        "# === EMD analysis (Table 3-style bias check on labels) ===\n",
        "def compute_emd_pvalue(df, group_col='male', subgroup_value=0, label_col='TenYearCHD', n_iter=10000, rng=None):\n",
        "    rng = np.random.default_rng(seed if rng is None else rng)\n",
        "    all_labels = df[label_col].values\n",
        "    subgroup = df[df[group_col] == subgroup_value][label_col].values\n",
        "    observed_emd = wasserstein_distance(subgroup, all_labels)\n",
        "    boot_emd = []\n",
        "    for _ in range(n_iter):\n",
        "        boot_sub = rng.choice(all_labels, size=len(subgroup), replace=False)\n",
        "        boot_emd.append(wasserstein_distance(boot_sub, all_labels))\n",
        "    boot_emd = np.array(boot_emd)\n",
        "    p_val = np.mean(boot_emd >= observed_emd)\n",
        "    return observed_emd, p_val\n",
        "\n",
        "female_emd, female_p = compute_emd_pvalue(dataset, subgroup_value=0)\n",
        "male_emd, male_p     = compute_emd_pvalue(dataset, subgroup_value=1)\n",
        "\n",
        "emd_summary = pd.DataFrame({\n",
        "    'Group': ['Female', 'Male'],\n",
        "    'EMD':   [female_emd, male_emd],\n",
        "    'p_value': [female_p, male_p],\n",
        "    'Bias? (p<=0.05)': ['Yes' if female_p <= 0.05 else 'No',\n",
        "                        'Yes' if male_p <= 0.05 else 'No']\n",
        "})\n",
        "\n",
        "print(\"\\nGender Bias EMD Results:\")\n",
        "print(emd_summary)\n",
        "\n",
        "# === Fairness metrics across gender (train on ALL data; between-group gaps) ===\n",
        "def safe_rate(numer, denom):\n",
        "    return numer / denom if denom > 0 else 0.0\n",
        "\n",
        "def rates(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "    if cm.size == 4:\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "    else:\n",
        "        TN = FP = FN = TP = 0\n",
        "    TPR = safe_rate(TP, TP+FN)\n",
        "    FPR = safe_rate(FP, FP+TN)\n",
        "    FNR = safe_rate(FN, TP+FN)\n",
        "    TNR = safe_rate(TN, TN+FP)\n",
        "    return dict(TP=TP, TN=TN, FP=FP, FN=FN, TPR=TPR, FPR=FPR, FNR=FNR, TNR=TNR)\n",
        "\n",
        "def fairness_from_groups(y_true, y_pred, y_prob, group_mask):\n",
        "    \"\"\"Compute group-wise and disparity metrics (Female=0, Male=1).\"\"\"\n",
        "    g0 = (group_mask == 0)  # Female\n",
        "    g1 = (group_mask == 1)  # Male\n",
        "\n",
        "    r0 = rates(y_true[g0], y_pred[g0])\n",
        "    r1 = rates(y_true[g1], y_pred[g1])\n",
        "\n",
        "    # Positive prediction rates\n",
        "    ppr0 = np.mean(y_pred[g0] == 1) if np.any(g0) else 0.0\n",
        "    ppr1 = np.mean(y_pred[g1] == 1) if np.any(g1) else 0.0\n",
        "\n",
        "    # Discrimination score (difference in mean positive probability)\n",
        "    if y_prob is not None:\n",
        "        dscore = float(np.nan_to_num(np.mean(y_prob[g1]) - np.mean(y_prob[g0])))\n",
        "    else:\n",
        "        dscore = float(ppr1 - ppr0)  # fallback\n",
        "\n",
        "    # Core fairness metrics\n",
        "    demographic_parity = abs(ppr1 - ppr0)\n",
        "    disparate_impact   = (ppr0 / ppr1) if ppr1 > 0 else np.nan  # avoid inf -> NaN\n",
        "    eo_tpr_gap         = abs(r1['TPR'] - r0['TPR'])\n",
        "    eo_fpr_gap         = abs(r1['FPR'] - r0['FPR'])\n",
        "    equal_opportunity  = eo_tpr_gap\n",
        "    fpr_parity         = eo_fpr_gap\n",
        "    ratio0             = (r0['FN']/r0['FP']) if r0['FP'] > 0 else np.nan\n",
        "    ratio1             = (r1['FN']/r1['FP']) if r1['FP'] > 0 else np.nan\n",
        "    treatment_eq       = abs(ratio1 - ratio0) if np.isfinite(ratio0) and np.isfinite(ratio1) else np.nan\n",
        "    ber0               = 0.5 * (r0['FNR'] + r0['FPR'])\n",
        "    ber1               = 0.5 * (r1['FNR'] + r1['FPR'])\n",
        "    ber_mean           = 0.5 * (ber0 + ber1)\n",
        "\n",
        "    return {\n",
        "        'Demographic parity (|ΔP(Ŷ=1)|)': demographic_parity,\n",
        "        'Disparate Impact (P(Ŷ=1|F)/P(Ŷ=1|M))': disparate_impact,\n",
        "        'Equalised odds |ΔTPR|': eo_tpr_gap,\n",
        "        'Equalised odds |ΔFPR|': eo_fpr_gap,\n",
        "        'Equal opportunity |ΔTPR|': equal_opportunity,\n",
        "        'FPR parity |ΔFPR|': fpr_parity,\n",
        "        'Treatment equality |Δ(FN/FP)|': treatment_eq,\n",
        "        'Discrimination score Δ mean ŷ_prob (M−F)': dscore,\n",
        "        'Balanced Error Rate (mean)': ber_mean,\n",
        "        'BER_Female': ber0,\n",
        "        'BER_Male': ber1,\n",
        "        'PPR_Female': ppr0,\n",
        "        'PPR_Male': ppr1,\n",
        "        'TPR_Female': r0['TPR'],\n",
        "        'TPR_Male': r1['TPR'],\n",
        "        'FPR_Female': r0['FPR'],\n",
        "        'FPR_Male': r1['FPR'],\n",
        "    }\n",
        "\n",
        "def evaluate_fairness_models(X_all, y_all, group_mask, models_dict, n_splits=5, random_state=seed):\n",
        "    \"\"\"Stratified K-fold; compute fairness metrics per fold and average.\"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    rows = []\n",
        "    for name, clf in models_dict.items():\n",
        "        fold_metrics = []\n",
        "        for train_idx, test_idx in skf.split(X_all, y_all):\n",
        "            Xtr, Xte = X_all[train_idx], X_all[test_idx]\n",
        "            ytr, yte = y_all[train_idx], y_all[test_idx]\n",
        "            gte = group_mask[test_idx] if isinstance(group_mask, np.ndarray) else group_mask.iloc[test_idx].values\n",
        "\n",
        "            clf.fit(Xtr, ytr)\n",
        "            yhat = clf.predict(Xte)\n",
        "\n",
        "            prob = None\n",
        "            if hasattr(clf, \"predict_proba\"):\n",
        "                prob = clf.predict_proba(Xte)[:, 1]\n",
        "            elif hasattr(clf, \"decision_function\"):\n",
        "                z = clf.decision_function(Xte)\n",
        "                prob = 1/(1+np.exp(-z))\n",
        "\n",
        "            fm = fairness_from_groups(yte, yhat, prob, gte)\n",
        "            fold_metrics.append(fm)\n",
        "\n",
        "        avg = pd.DataFrame(fold_metrics).mean(numeric_only=True).to_dict()\n",
        "        avg['Model'] = name\n",
        "        rows.append(avg)\n",
        "\n",
        "    df = pd.DataFrame(rows).set_index('Model').sort_index()\n",
        "    return df\n",
        "\n",
        "group_mask_int = dataset['male'].astype(int).values  # 1=Male, 0=Female\n",
        "fair_df = evaluate_fairness_models(X_scaled, y, group_mask_int, models, n_splits=5, random_state=seed)\n",
        "\n",
        "# Reorder columns to focus on requested metrics\n",
        "fairness_summary = fair_df[[\n",
        "    'Demographic parity (|ΔP(Ŷ=1)|)',\n",
        "    'Equalised odds |ΔTPR|',\n",
        "    'Equalised odds |ΔFPR|',\n",
        "    'Equal opportunity |ΔTPR|',\n",
        "    'FPR parity |ΔFPR|',\n",
        "    'Treatment equality |Δ(FN/FP)|',\n",
        "    'Discrimination score Δ mean ŷ_prob (M−F)',\n",
        "    'Disparate Impact (P(Ŷ=1|F)/P(Ŷ=1|M))',\n",
        "    'Balanced Error Rate (mean)',\n",
        "    'BER_Female', 'BER_Male',\n",
        "    'PPR_Female', 'PPR_Male',\n",
        "    'TPR_Female', 'TPR_Male',\n",
        "    'FPR_Female', 'FPR_Male'\n",
        "]].copy()\n",
        "\n",
        "print(\"\\n=== Fairness Summary (avg over 5 folds) ===\")\n",
        "print(fairness_summary.round(3))\n",
        "\n",
        "# === Permutation tests for p-values on three key metrics ===\n",
        "def permutation_pvalue(X, y, group_mask, model, metric_key, n_iter=500, random_state=42):\n",
        "    \"\"\"\n",
        "    Compute p-value for a fairness metric via permutation of group labels.\n",
        "    metric_key is one of:\n",
        "      'Discrimination score Δ mean ŷ_prob (M−F)',\n",
        "      'Disparate Impact (P(Ŷ=1|F)/P(Ŷ=1|M))',\n",
        "      'Balanced Error Rate (mean)'\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "\n",
        "    # observed\n",
        "    obs_vals = []\n",
        "    for tr, te in skf.split(X, y):\n",
        "        model.fit(X[tr], y[tr])\n",
        "        yhat = model.predict(X[te])\n",
        "        prob = None\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            prob = model.predict_proba(X[te])[:,1]\n",
        "        elif hasattr(model, \"decision_function\"):\n",
        "            z = model.decision_function(X[te])\n",
        "            prob = 1/(1+np.exp(-z))\n",
        "        fm = fairness_from_groups(y[te], yhat, prob, group_mask[te])\n",
        "        obs_vals.append(fm[metric_key])\n",
        "    observed = float(np.nanmean(obs_vals))\n",
        "\n",
        "    # null distribution by shuffling group labels\n",
        "    null_vals = []\n",
        "    for _ in range(n_iter):\n",
        "        shuffled = rng.permutation(group_mask)\n",
        "        fold_vals = []\n",
        "        for tr, te in skf.split(X, y):\n",
        "            model.fit(X[tr], y[tr])\n",
        "            yhat = model.predict(X[te])\n",
        "            prob = None\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                prob = model.predict_proba(X[te])[:,1]\n",
        "            elif hasattr(model, \"decision_function\"):\n",
        "                z = model.decision_function(X[te])\n",
        "                prob = 1/(1+np.exp(-z))\n",
        "            fm = fairness_from_groups(y[te], yhat, prob, shuffled[te])\n",
        "            fold_vals.append(fm[metric_key])\n",
        "        null_vals.append(np.nanmean(fold_vals))\n",
        "\n",
        "    null_vals = np.array(null_vals, dtype=float)\n",
        "\n",
        "    # For gap metrics (absolute differences), we use a right-tail p-value\n",
        "    # For DI (a ratio near 1 is \"fair\"), use two-sided around 1.0\n",
        "    if metric_key == 'Disparate Impact (P(Ŷ=1|F)/P(Ŷ=1|M))':\n",
        "        # distance from 1\n",
        "        obs_d = abs(observed - 1.0)\n",
        "        null_d = np.abs(null_vals - 1.0)\n",
        "        p_val = np.mean(null_d >= obs_d)\n",
        "    else:\n",
        "        p_val = np.mean(null_vals >= observed)\n",
        "\n",
        "    return observed, float(p_val)\n",
        "\n",
        "# Build p-value table for three key metrics\n",
        "rows = []\n",
        "metric_keys = [\n",
        "    'Discrimination score Δ mean ŷ_prob (M−F)',\n",
        "    'Disparate Impact (P(Ŷ=1|F)/P(Ŷ=1|M))',\n",
        "    'Balanced Error Rate (mean)'\n",
        "]\n",
        "\n",
        "for name, clf in models.items():\n",
        "    entry = {'Model': name}\n",
        "    for mk in metric_keys:\n",
        "        obs, p = permutation_pvalue(X_scaled, y, group_mask_int, clf, mk, n_iter=500, random_state=seed)\n",
        "        entry[f'{mk}'] = obs\n",
        "        entry[f'{mk} p-value'] = p\n",
        "    rows.append(entry)\n",
        "\n",
        "pval_table = pd.DataFrame(rows).set_index('Model').sort_index()\n",
        "\n",
        "print(\"\\n=== Key Fairness Metrics with p-values (avg over CV, permutation test) ===\")\n",
        "print(pval_table.round(4))\n",
        "\n",
        "# === Print compact key metrics to console ===\n",
        "print(\"\\n=== Key Fairness Metrics (Discrimination, DI, BER) ===\")\n",
        "for model in pval_table.index:\n",
        "    dscore = pval_table.loc[model, 'Discrimination score Δ mean ŷ_prob (M−F)']\n",
        "    disp   = pval_table.loc[model, 'Disparate Impact (P(Ŷ=1|F)/P(Ŷ=1|M))']\n",
        "    ber    = pval_table.loc[model, 'Balanced Error Rate (mean)']\n",
        "    pdv1   = pval_table.loc[model, 'Discrimination score Δ mean ŷ_prob (M−F) p-value']\n",
        "    pdv2   = pval_table.loc[model, 'Disparate Impact (P(Ŷ=1|F)/P(Ŷ=1|M)) p-value']\n",
        "    pdv3   = pval_table.loc[model, 'Balanced Error Rate (mean) p-value']\n",
        "    print(f\"\\nModel: {model}\")\n",
        "    print(f\"  Discrimination Score : {dscore:.4f}  (p={pdv1:.4f})\")\n",
        "    print(f\"  Disparate Impact     : {disp:.4f}  (p={pdv2:.4f})\")\n",
        "    print(f\"  Balanced Error Rate  : {ber:.4f}  (p={pdv3:.4f})\")\n",
        "\n",
        "# === Save all outputs into one Excel file ===\n",
        "out_file = 'results.xlsx'\n",
        "with pd.ExcelWriter(out_file, mode='w') as xlw:\n",
        "    group_kfold_df.to_excel(xlw, sheet_name='group_kfold', index=False)\n",
        "    fairness_summary.round(6).to_excel(xlw, sheet_name='fairness_summary')\n",
        "    emd_summary.round(6).to_excel(xlw, sheet_name='emd_summary', index=False)\n",
        "    pval_table.round(6).to_excel(xlw, sheet_name='key_metrics_pvalues')\n",
        "\n",
        "print(f\"\\nSaved all results to {out_file} (sheets: group_kfold, fairness_summary, emd_summary, key_metrics_pvalues)\")"
      ],
      "metadata": {
        "id": "W5aDtAaPQfkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d923b7a-6e1b-43ba-ef79-5a48a3b44b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Female Group (20-fold)\n",
            "Running Male Group (20-fold)\n",
            "\n",
            "Gender Bias EMD Results:\n",
            "    Group       EMD  p_value Bias? (p<=0.05)\n",
            "0  Female  0.005605   0.2631              No\n",
            "1    Male  0.007490   0.2567              No\n",
            "\n",
            "=== Fairness Summary (avg over 5 folds) ===\n",
            "       Demographic parity (|ΔP(Ŷ=1)|)  Equalised odds |ΔTPR|  \\\n",
            "Model                                                          \n",
            "ANN                             0.022                  0.042   \n",
            "DT                              0.018                  0.076   \n",
            "KNN                             0.014                  0.056   \n",
            "LR                              0.005                  0.037   \n",
            "RF                              0.009                  0.024   \n",
            "SVM                             0.004                  0.005   \n",
            "\n",
            "       Equalised odds |ΔFPR|  Equal opportunity |ΔTPR|  FPR parity |ΔFPR|  \\\n",
            "Model                                                                       \n",
            "ANN                    0.020                     0.042              0.020   \n",
            "DT                     0.021                     0.076              0.021   \n",
            "KNN                    0.013                     0.056              0.013   \n",
            "LR                     0.003                     0.037              0.003   \n",
            "RF                     0.008                     0.024              0.008   \n",
            "SVM                    0.004                     0.005              0.004   \n",
            "\n",
            "       Treatment equality |Δ(FN/FP)|  \\\n",
            "Model                                  \n",
            "ANN                            2.724   \n",
            "DT                             0.141   \n",
            "KNN                            4.974   \n",
            "LR                             7.000   \n",
            "RF                            30.375   \n",
            "SVM                           35.667   \n",
            "\n",
            "       Discrimination score Δ mean ŷ_prob (M−F)  \\\n",
            "Model                                             \n",
            "ANN                                       0.011   \n",
            "DT                                        0.016   \n",
            "KNN                                       0.022   \n",
            "LR                                        0.013   \n",
            "RF                                        0.007   \n",
            "SVM                                       0.001   \n",
            "\n",
            "       Disparate Impact (P(Ŷ=1|F)/P(Ŷ=1|M))  Balanced Error Rate (mean)  \\\n",
            "Model                                                                     \n",
            "ANN                                   1.042                       0.465   \n",
            "DT                                    0.908                       0.452   \n",
            "KNN                                   1.129                       0.474   \n",
            "LR                                    1.544                       0.480   \n",
            "RF                                    2.656                       0.481   \n",
            "SVM                                   0.373                       0.498   \n",
            "\n",
            "       BER_Female  BER_Male  PPR_Female  PPR_Male  TPR_Female  TPR_Male  \\\n",
            "Model                                                                     \n",
            "ANN         0.455     0.474       0.042     0.047       0.120     0.091   \n",
            "DT          0.455     0.449       0.138     0.153       0.216     0.241   \n",
            "KNN         0.464     0.483       0.025     0.028       0.088     0.057   \n",
            "LR          0.481     0.480       0.010     0.008       0.044     0.043   \n",
            "RF          0.477     0.486       0.015     0.009       0.056     0.033   \n",
            "SVM         0.497     0.499       0.003     0.003       0.008     0.005   \n",
            "\n",
            "       FPR_Female  FPR_Male  \n",
            "Model                        \n",
            "ANN         0.031     0.040  \n",
            "DT          0.127     0.139  \n",
            "KNN         0.016     0.024  \n",
            "LR          0.005     0.002  \n",
            "RF          0.010     0.005  \n",
            "SVM         0.003     0.002  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j5yjweyy1igS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}